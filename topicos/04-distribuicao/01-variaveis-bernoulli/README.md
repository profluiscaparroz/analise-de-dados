# Vari√°veis Aleat√≥rias Discretas (VAD)

### O que s√£o?

Uma **vari√°vel aleat√≥ria discreta** √© uma fun√ß√£o que atribui um n√∫mero real a cada resultado poss√≠vel de um experimento aleat√≥rio, com a caracter√≠stica de que essa vari√°vel pode assumir apenas **valores distintos e cont√°veis**. Isso significa que podemos listar todos os valores poss√≠veis que a vari√°vel pode tomar, mesmo que essa lista seja infinita (como os n√∫meros naturais $1, 2, 3, \dots$).

Na pr√°tica, a vari√°vel aleat√≥ria discreta √© usada para **quantificar eventos aleat√≥rios**, permitindo a aplica√ß√£o de ferramentas matem√°ticas (como a probabilidade, esperan√ßa, vari√¢ncia) para estudar os comportamentos esperados e as incertezas de um processo aleat√≥rio.

> A palavra "aleat√≥ria" indica que o valor assumido pela vari√°vel depende de um fen√¥meno **n√£o determin√≠stico**, ou seja, de um experimento cujos resultados n√£o podem ser previstos com certeza antes da realiza√ß√£o.

> A palavra "discreta" significa que a vari√°vel **n√£o assume valores cont√≠nuos** (como qualquer n√∫mero real em um intervalo), mas sim **valores pontuais e isolados**.

### Exemplos cl√°ssicos:

* O n√∫mero obtido ao lan√ßar um dado ($X \in \{1, 2, 3, 4, 5, 6\}$).
* O n√∫mero de filhos em uma fam√≠lia.
* O n√∫mero de chamadas recebidas por uma central em uma hora.
* O resultado de um teste que retorna "positivo" ou "negativo" (representado por 1 ou 0).

### Representa√ß√£o formal:

Seja $S$ o espa√ßo amostral de um experimento (o conjunto de todos os resultados poss√≠veis). Uma **vari√°vel aleat√≥ria discreta $X$** √© uma fun√ß√£o:

$
X: S \rightarrow \mathbb{R}
$

tal que o conjunto dos valores poss√≠veis $\{x_1, x_2, \dots\} \subset \mathbb{R}$ √© finito ou enumer√°vel.

Por exemplo, ao jogar dois dados, o espa√ßo amostral tem 36 pares ordenados, mas uma vari√°vel aleat√≥ria pode representar a **soma dos valores dos dados**, que varia de 2 a 12. Ou seja, o espa√ßo amostral √© complexo, mas a vari√°vel aleat√≥ria nos ajuda a extrair e analisar um aspecto espec√≠fico desse espa√ßo ‚Äî nesse caso, a soma dos dados.

### Por que s√£o importantes?

As vari√°veis aleat√≥rias discretas s√£o fundamentais em:

* **Modelagem estat√≠stica**, onde muitos fen√¥menos reais envolvem contagens ou decis√µes bin√°rias.
* **Teoria da probabilidade**, como base para outras distribui√ß√µes (binomial, geom√©trica, Poisson).
* **Ci√™ncia de dados e IA**, onde eventos discretos como cliques, falhas, aprova√ß√µes, etc., s√£o representados por vari√°veis discretas.
* **Engenharia e computa√ß√£o**, como em redes de filas, processos estoc√°sticos, codifica√ß√£o e criptografia.


### Caracter√≠sticas principais:

Uma **vari√°vel aleat√≥ria discreta (VAD)** √© definida por suas propriedades matem√°ticas e probabil√≠sticas fundamentais, que a distinguem de outros tipos de vari√°veis (como as cont√≠nuas). As principais caracter√≠sticas s√£o:

---

#### üîπ 1. Conjunto de valores **finito ou enumer√°vel**

Isso significa que a vari√°vel aleat√≥ria pode assumir apenas um n√∫mero **cont√°vel** de valores distintos. Os valores podem ser:

* Um conjunto **finito**, como $\{0, 1\}$, $\{1, 2, 3, 4, 5, 6\}$, etc.
* Um conjunto **infinito enumer√°vel**, como os n√∫meros naturais $\mathbb{N} = \{0, 1, 2, 3, \dots\}$.

Esse conjunto √© chamado de **suporte** da vari√°vel aleat√≥ria, e √© onde sua fun√ß√£o de probabilidade √© diferente de zero.

> üìå Exemplo:
> Se $X$ √© o n√∫mero de chamadas recebidas em uma central de atendimento por minuto, ent√£o $X \in \{0, 1, 2, 3, ...\}$ ‚Äî conjunto infinito enumer√°vel.

---

#### üîπ 2. Cada valor tem uma **probabilidade associada**

A vari√°vel aleat√≥ria discreta √© definida por sua **fun√ß√£o de probabilidade de massa** (f.p.m.), ou em ingl√™s **Probability Mass Function (PMF)**. Essa fun√ß√£o √© uma associa√ß√£o:

$
f(x) = P(X = x), \quad \text{para cada } x \in \text{suporte de } X
$

Ou seja, para cada valor $x$ que $X$ pode assumir, existe uma probabilidade $P(X = x)$, tal que:

* $0 \leq P(X = x) \leq 1$ (todas as probabilidades s√£o v√°lidas)
* A soma das probabilidades √© igual a 1:

$
\sum_{x \in \text{suporte}} P(X = x) = 1
$

> üé≤ Exemplo (lan√ßamento de um dado justo):
> A vari√°vel $X \in \{1, 2, 3, 4, 5, 6\}$ tem:
>
> $
> P(X = x) = \frac{1}{6}, \quad \text{para todo } x
> $

---

#### üîπ 3. O comportamento de $X$ pode ser descrito por **propriedades estat√≠sticas**

Uma vari√°vel aleat√≥ria discreta permite o c√°lculo de medidas importantes como:

* **Esperan√ßa matem√°tica (valor esperado)**:

  $
  \mathbb{E}[X] = \sum_{x} x \cdot P(X = x)
  $

  Interpreta-se como a m√©dia ponderada dos valores poss√≠veis, de acordo com suas probabilidades.

* **Vari√¢ncia**:

  $
  \text{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2] = \sum_{x} (x - \mathbb{E}[X])^2 \cdot P(X = x)
  $

  Mede a dispers√£o dos valores em torno da m√©dia.

* **Moda** (valor com maior probabilidade), **mediana**, **fun√ß√£o de distribui√ß√£o acumulada (FDA ou CDF)**, entre outras.

---

#### üîπ 4. S√£o base para modelagem de muitos fen√¥menos discretos

Vari√°veis aleat√≥rias discretas s√£o amplamente usadas para modelar:

* **Contagens** (n√∫mero de eventos, chamadas, falhas, etc.)
* **Experimentos com resultado bin√°rio** (sucesso/fracasso)
* **Jogos de azar** (dados, moedas, cartas)
* **Processos estoc√°sticos discretos** (cadeias de Markov)
* **Modelos probabil√≠sticos de algoritmos** (randomiza√ß√£o, hashing, simula√ß√µes de Monte Carlo)

---

## O que √© a Fun√ß√£o de Probabilidade de Massa (PMF)?

A **fun√ß√£o de probabilidade de massa** √© a forma como **atribu√≠mos probabilidades a cada valor** poss√≠vel de uma **vari√°vel aleat√≥ria discreta**.

Formalmente, para uma vari√°vel aleat√≥ria discreta $X$, a PMF √© uma fun√ß√£o $f$ tal que:

$
f(x) = P(X = x), \quad \text{para cada } x \text{ no suporte de } X
$

Essa fun√ß√£o precisa satisfazer duas condi√ß√µes fundamentais:

1. **N√£o-negatividade:**

   $
   P(X = x) \geq 0 \quad \text{para todo } x
   $

2. **Soma das probabilidades igual a 1:**

   $
   \sum_{x \in \text{suporte}} P(X = x) = 1
   $

---

### Exemplo Passo a Passo: Jogar um dado justo de 6 lados

### Etapa 1: Definir o experimento

> Lan√ßamento de um dado comum, com 6 faces numeradas de 1 a 6.

### Etapa 2: Definir a vari√°vel aleat√≥ria

> Seja $X$ a vari√°vel aleat√≥ria que representa o **n√∫mero obtido** ao lan√ßar o dado.

Ent√£o:

$
X \in \{1, 2, 3, 4, 5, 6\}
$

### Etapa 3: Atribuir probabilidades

Como o dado √© **justo**, todos os valores t√™m **igual chance** de acontecer. Como h√° 6 possibilidades:

$
P(X = x) = \frac{1}{6}, \quad \text{para todo } x \in \{1, 2, 3, 4, 5, 6\}
$

---

### Etapa 4: Montar a Tabela da PMF

| $x$ | $P(X = x)$    |
| --- | ------------- |
| 1   | $\frac{1}{6}$ |
| 2   | $\frac{1}{6}$ |
| 3   | $\frac{1}{6}$ |
| 4   | $\frac{1}{6}$ |
| 5   | $\frac{1}{6}$ |
| 6   | $\frac{1}{6}$ |

---

### Etapa 5: Verificar propriedades da PMF

1. **N√£o-negatividade:**
   Todas as probabilidades s√£o $\frac{1}{6} > 0$ ‚Üí ok.

2. **Soma das probabilidades:**

   $
   \sum_{x=1}^6 P(X = x) = 6 \cdot \frac{1}{6} = 1
   $

   ‚Üí ok.

---

### Etapa 6: Usar a PMF para c√°lculos

####  C√°lculo da esperan√ßa (valor esperado):

$
\mathbb{E}[X] = \sum_{x=1}^6 x \cdot P(X = x) = \sum_{x=1}^6 x \cdot \frac{1}{6}
= \frac{1}{6}(1 + 2 + 3 + 4 + 5 + 6) = \frac{21}{6} = 3{,}5
$

#### C√°lculo da vari√¢ncia:

$
\text{Var}(X) = \sum_{x=1}^6 (x - 3{,}5)^2 \cdot \frac{1}{6}
$

Calculando os termos individualmente:

| $x$ | $(x - 3{,}5)^2$ |
| --- | --------------- |
| 1   | $6{,}25$        |
| 2   | $2{,}25$        |
| 3   | $0{,}25$        |
| 4   | $0{,}25$        |
| 5   | $2{,}25$        |
| 6   | $6{,}25$        |

Somando:

$
\text{Var}(X) = \frac{1}{6} (6{,}25 + 2{,}25 + 0{,}25 + 0{,}25 + 2{,}25 + 6{,}25) = \frac{17{,}5}{6} = 2{,}9167
$

---

A fun√ß√£o de probabilidade de massa (PMF) √© uma **ferramenta essencial** na estat√≠stica e probabilidade, pois permite:

* Mapear os **valores poss√≠veis** de uma vari√°vel aleat√≥ria para suas **respectivas probabilidades**.
* Fazer **c√°lculos anal√≠ticos** como esperan√ßa, vari√¢ncia e distribui√ß√£o acumulada.
* Aplicar modelos estat√≠sticos para simular ou prever comportamentos.

Esse exemplo do dado √© um **caso cl√°ssico de PMF equiprov√°vel**, mas podemos fazer o mesmo com distribui√ß√µes **n√£o uniformes**, como a Bernoulli, binomial, geom√©trica, etc.

---

## 2. Distribui√ß√£o Equiprov√°vel (ou uniforme discreta)

### Defini√ß√£o Formal

A **distribui√ß√£o uniforme discreta**, tamb√©m conhecida como **distribui√ß√£o equiprov√°vel discreta**, ocorre quando uma vari√°vel aleat√≥ria discreta $X$ pode assumir $n$ valores distintos e **todos t√™m a mesma probabilidade de ocorr√™ncia**. Isto √©, n√£o h√° nenhum vi√©s ou prefer√™ncia entre os valores poss√≠veis: o sistema √© **completamente sim√©trico** do ponto de vista probabil√≠stico.

Seja o espa√ßo amostral finito:

$
S = \{x_1, x_2, \dots, x_n\}
$

Ent√£o:

$
P(X = x_i) = \frac{1}{n} \quad \text{para todo } i = 1, 2, ..., n
$

### Interpreta√ß√£o Intuitiva

Imagine uma urna com $n$ bolas numeradas de 1 at√© $n$, todas do mesmo tamanho e sem marca√ß√µes externas. Se voc√™ sortear uma bola sem olhar, a chance de qualquer n√∫mero aparecer √© exatamente $\frac{1}{n}$. Isso √© uma distribui√ß√£o equiprov√°vel.

√â a base conceitual para definir o que chamamos de "experimento justo".

---

### Representa√ß√£o Gr√°fica

A fun√ß√£o de massa de probabilidade (f.p.m.) de uma distribui√ß√£o uniforme discreta pode ser representada por um gr√°fico de **barras com a mesma altura**.

Exemplo: $X \sim \text{Uniforme}(1, 5)$

Valores poss√≠veis: $\{1, 2, 3, 4, 5\}$
Probabilidades: $P(X = x) = 0{,}2$ para cada $x$

Gr√°fico:

```
 P(X=x)
   |
 0.2 | ‚ñà ‚ñà ‚ñà ‚ñà ‚ñà
     +------------
        1 2 3 4 5
```

---

### üìä Fun√ß√£o de Distribui√ß√£o Acumulada (F.D.A)

A fun√ß√£o acumulada $F(x) = P(X \leq x)$ da distribui√ß√£o uniforme discreta √© uma **fun√ß√£o em degraus**. Para $X \sim \text{Uniforme}(a, b)$:

$
F(x) = 
\begin{cases}
0 & x < a \\
\frac{\lfloor x \rfloor - a + 1}{b - a + 1} & a \leq x \leq b \\
1 & x > b
\end{cases}
$

---

### üìà Esperan√ßa Matem√°tica

Se $X \in \{x_1, x_2, ..., x_n\}$ com todos os $x_i$ igualmente prov√°veis, a **esperan√ßa matem√°tica** (valor esperado ou m√©dia) √© dada por:

$
\mathbb{E}[X] = \sum_{i=1}^{n} x_i \cdot \frac{1}{n} = \frac{1}{n} \sum_{i=1}^{n} x_i
$

**Caso cl√°ssico:**
Se $X \in \{1, 2, ..., n\}$:

$
\mathbb{E}[X] = \frac{1 + 2 + \cdots + n}{n} = \frac{n+1}{2}
$

---

### üìâ Vari√¢ncia

A vari√¢ncia mede o quanto os valores da vari√°vel aleat√≥ria se afastam da m√©dia.

$
\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2
$

Para $X \in \{1, 2, ..., n\}$, a f√≥rmula fechada √©:

$
\text{Var}(X) = \frac{(n^2 - 1)}{12}
$

üëâ Isso deriva da soma dos quadrados dos $n$ primeiros n√∫meros naturais:

$
\mathbb{E}[X^2] = \frac{1}{n} \sum_{i=1}^{n} i^2 = \frac{(n+1)(2n+1)}{6n}
$

---

### Entropia

A **entropia** $H(X)$, que mede a incerteza associada √† distribui√ß√£o, √© m√°xima quando os eventos s√£o equiprov√°veis:

$
H(X) = -\sum_{i=1}^{n} \frac{1}{n} \log_2\left(\frac{1}{n}\right) = \log_2(n)
$

Portanto, quanto maior $n$, maior a incerteza.

---

### Aplica√ß√µes

#### üß™ 1. Teoria das Probabilidades

* Ponto de partida para definir espa√ßo amostral e eventos equiprov√°veis.
* Defini√ß√£o de **probabilidade cl√°ssica**:

  $
  P(A) = \frac{\text{n√∫mero de casos favor√°veis}}{\text{n√∫mero total de casos poss√≠veis}}
  $

#### üïπ 2. Jogos e Simula√ß√µes

* Lan√ßamento de dados (6 valores).
* Roletas, cartas, loterias.
* Gera√ß√£o de n√∫meros aleat√≥rios simulando cen√°rios onde todos os casos t√™m a mesma chance.

#### ü§ñ 3. Computa√ß√£o e Algoritmos

* Algoritmos de embaralhamento (ex: Fisher-Yates).
* Distribui√ß√£o base para **random walk** e simula√ß√µes Monte Carlo.
* Balanceamento de carga aleat√≥ria.

#### üßÆ 4. Infer√™ncia e Estat√≠stica

* Amostragem aleat√≥ria simples: escolher unidades da popula√ß√£o com igual probabilidade.
* Testes estat√≠sticos onde a hip√≥tese nula assume distribui√ß√£o uniforme dos resultados.

---

### üîÅ Extens√µes

* **Uniforme Cont√≠nua:** Quando os valores poss√≠veis formam um intervalo cont√≠nuo $[a, b]$, com densidade constante $f(x) = \frac{1}{b - a}$.
* **Multivariada Uniforme Discreta:** Vari√°veis vetoriais onde todos os vetores de um dom√≠nio discreto t√™m mesma chance de serem observados.

---

A **distribui√ß√£o uniforme discreta** √© um **modelo fundamental e sim√©trico** na teoria das probabilidades. Ela √© simples, mas extremamente √∫til, aparecendo em contextos did√°ticos, computacionais e estat√≠sticos. A igualdade de chances entre os valores poss√≠veis a torna um **modelo neutro de refer√™ncia**, essencial para modelagem inicial de incerteza, simula√ß√£o e infer√™ncia estat√≠stica.

1. Definir a vari√°vel aleat√≥ria com $n$ valores igualmente prov√°veis.
2. Simular valores com `numpy`.
3. Plotar a distribui√ß√£o de frequ√™ncias com `matplotlib`.
4. Calcular a m√©dia e a vari√¢ncia emp√≠ricas e comparar com os valores te√≥ricos.

---

### Exemplo pr√°tico: Lan√ßamento de uma moeda viciada

### Cen√°rio

Imagine uma moeda que n√£o √© justa ‚Äî ela tem 70% de chance de dar **cara** e 30% de chance de dar **coroa**. Queremos modelar essa situa√ß√£o usando uma vari√°vel aleat√≥ria Bernoulli, onde:

* **Sucesso (X = 1):** sair cara
* **Fracasso (X = 0):** sair coroa

Assim, $p = 0.7$.

---

### Passo 1: Definir a vari√°vel aleat√≥ria $X$

Definimos $X$ como:

$
X = \begin{cases}
1 & \text{se sair cara} \\
0 & \text{se sair coroa}
\end{cases}
$

---

### Passo 2: Escrever a fun√ß√£o de probabilidade

A fun√ß√£o de massa de probabilidade √©:

$
P(X = x) = p^x (1 - p)^{1 - x}, \quad x \in \{0,1\}
$

Para nosso caso:

* $P(X=1) = 0.7$
* $P(X=0) = 0.3$

---

### Passo 3: Calcular a esperan√ßa (valor esperado)

$
\mathbb{E}[X] = 1 \times P(X=1) + 0 \times P(X=0) = 1 \times 0.7 + 0 \times 0.3 = 0.7
$

Interpreta√ß√£o: Em muitos lan√ßamentos, a m√©dia de caras ser√° 70%.

---

### Passo 4: Calcular a vari√¢ncia

$
\text{Var}(X) = p(1-p) = 0.7 \times 0.3 = 0.21
$

Isso mede a variabilidade dos resultados.

---

### Passo 5: Interpretar resultados

* A moeda tem alta probabilidade de dar cara (70%).
* Em muitas repeti√ß√µes, a m√©dia de caras ser√° pr√≥xima a 0.7.
* A vari√¢ncia indica que h√° alguma dispers√£o (n√£o √© 0, logo nem sempre sai cara).

---

### Passo 6: Simular 10 lan√ßamentos (exemplo)

Suponha que lan√ßamos essa moeda 10 vezes, observando $X_i$ em cada lan√ßamento.

| Lan√ßamento | Resultado (X\_i) |
| ---------- | ---------------- |
| 1          | 1 (cara)         |
| 2          | 0 (coroa)        |
| 3          | 1 (cara)         |
| 4          | 1 (cara)         |
| 5          | 0 (coroa)        |
| 6          | 1 (cara)         |
| 7          | 1 (cara)         |
| 8          | 0 (coroa)        |
| 9          | 1 (cara)         |
| 10         | 1 (cara)         |

N√∫mero de caras: 7 (ou seja, 7 sucessos)

M√©dia amostral: $\frac{7}{10} = 0.7$, exatamente o valor esperado!

### üß™ Exemplo em Python

```python
import numpy as np
import matplotlib.pyplot as plt

# Par√¢metros da distribui√ß√£o
a = 1           # menor valor
b = 6           # maior valor
n = b - a + 1   # n√∫mero de valores poss√≠veis

# N√∫mero de simula√ß√µes
N = 100_000

# Simula√ß√£o da vari√°vel aleat√≥ria uniforme discreta
valores = np.random.randint(a, b + 1, size=N)

# C√°lculo das frequ√™ncias relativas (probabilidades emp√≠ricas)
valores_unicos, contagens = np.unique(valores, return_counts=True)
frequencias_relativas = contagens / N

# C√°lculo te√≥rico
media_teorica = (a + b) / 2
variancia_teorica = ((b - a + 1)**2 - 1) / 12

# C√°lculo emp√≠rico
media_empirica = np.mean(valores)
variancia_empirica = np.var(valores)

# Impress√£o dos resultados
print(f"Valores poss√≠veis: {valores_unicos}")
print(f"Frequ√™ncias relativas: {frequencias_relativas}")
print(f"M√©dia te√≥rica: {media_teorica:.4f} | M√©dia emp√≠rica: {media_empirica:.4f}")
print(f"Vari√¢ncia te√≥rica: {variancia_teorica:.4f} | Vari√¢ncia emp√≠rica: {variancia_empirica:.4f}")

# Plotagem do gr√°fico de barras
plt.figure(figsize=(8, 4))
plt.bar(valores_unicos, frequencias_relativas, color='royalblue', edgecolor='black')
plt.axhline(y=1/n, color='red', linestyle='--', label=f'Prob. te√≥rica = {1/n:.2f}')
plt.title(f'Distribui√ß√£o Uniforme Discreta (a={a}, b={b})')
plt.xlabel('Valores')
plt.ylabel('Frequ√™ncia Relativa')
plt.legend()
plt.grid(True, axis='y', linestyle=':', alpha=0.7)
plt.tight_layout()
plt.show()
```

## Exemplo 1: Lan√ßamento de um dado - "obter n√∫mero 6"

### Cen√°rio

* Experimento: lan√ßar um dado justo de 6 faces.
* Definimos o sucesso como **"sair o n√∫mero 6"**.
* Resultado poss√≠vel da vari√°vel $X$:

  * $X = 1$ se sair 6 (sucesso).
  * $X = 0$ se sair outro n√∫mero (fracasso).

### Passo 1: Determinar $p$

Probabilidade de sucesso:

$
p = P(X=1) = P(\text{sair 6}) = \frac{1}{6} \approx 0,1667
$

Logo,

$
P(X=0) = 1 - p = \frac{5}{6} \approx 0,8333
$

### Passo 2: Escrever a fun√ß√£o de probabilidade

$
P(X=x) = p^{x} (1-p)^{1-x}, \quad x \in \{0,1\}
$

Ou seja,

* $P(X=1) = 0,1667$
* $P(X=0) = 0,8333$

### Passo 3: Calcular expectativa e vari√¢ncia

* Esperan√ßa:

$
\mathbb{E}[X] = p = 0,1667
$

Interpreta√ß√£o: em m√©dia, o dado ‚Äúsai 6‚Äù em cerca de 16,67% dos lan√ßamentos.

* Vari√¢ncia:

$
\text{Var}(X) = p(1-p) = 0,1667 \times 0,8333 = 0,1389
$

### Passo 4: Interpreta√ß√£o final

Esse modelo Bernoulli ajuda a responder perguntas do tipo: "Qual a chance de obter um 6 no dado em um lan√ßamento?", "Qual √© o comportamento esperado e variabilidade?".

---

## Exemplo 2: Um teste m√©dico para detectar uma doen√ßa

### Cen√°rio

* Um teste cl√≠nico detecta a doen√ßa em pacientes com 90% de efic√°cia (probabilidade de sucesso).
* Vari√°vel $X$:

  * $X = 1$ se o teste detectar corretamente a doen√ßa (sucesso).
  * $X = 0$ se o teste falhar (fracasso).

### Passo 1: Determinar $p$

$
p = 0.9
$

Logo,

$
P(X=1) = 0.9, \quad P(X=0) = 0.1
$

### Passo 2: Fun√ß√£o de probabilidade

$
P(X=x) = 0.9^{x} \times 0.1^{1-x}, \quad x \in \{0,1\}
$

* $P(X=1) = 0.9$
* $P(X=0) = 0.1$

### Passo 3: Calcular expectativa e vari√¢ncia

* Esperan√ßa:

$
\mathbb{E}[X] = p = 0.9
$

* Vari√¢ncia:

$
\text{Var}(X) = p(1-p) = 0.9 \times 0.1 = 0.09
$

### Passo 4: Interpreta√ß√£o

O teste √© muito eficiente, com alta chance de sucesso. A vari√¢ncia baixa indica que a chance de falha √© pequena.


---

### üìä Sa√≠da Esperada

* Um gr√°fico de barras onde todas as alturas (frequ√™ncias relativas) est√£o pr√≥ximas de $\frac{1}{n}$, indicando equiprobabilidade.
* Impress√£o da m√©dia e vari√¢ncia te√≥ricas e emp√≠ricas, que devem estar muito pr√≥ximas quando $N$ √© grande.

---

### üß† Explica√ß√£o

* `np.random.randint(a, b+1, size=N)` gera amostras da distribui√ß√£o uniforme discreta no intervalo $[a, b]$.
* `np.unique(..., return_counts=True)` contabiliza a frequ√™ncia de cada valor.
* As compara√ß√µes entre **teoria** e **simula√ß√£o** mostram como a distribui√ß√£o se comporta na pr√°tica.



---

## üü¢ 3. Distribui√ß√£o de Bernoulli

Claro! Vamos aprofundar bastante a se√ß√£o sobre a **Distribui√ß√£o de Bernoulli**, detalhando sua origem, propriedades matem√°ticas, interpreta√ß√µes, generaliza√ß√µes, exemplos pr√°ticos, e sua import√¢ncia no contexto estat√≠stico e computacional.

---

## üü¢ 3. Distribui√ß√£o de Bernoulli (vers√£o aprofundada)

### Introdu√ß√£o e contexto hist√≥rico

A distribui√ß√£o de Bernoulli √© uma das distribui√ß√µes probabil√≠sticas mais simples e fundamentais. Seu nome vem do matem√°tico su√≠√ßo **Jacob Bernoulli** (1654‚Äì1705), que foi um dos pioneiros no estudo da probabilidade e da an√°lise combinat√≥ria. A distribui√ß√£o modela o resultado de um experimento ou ensaio que possui exatamente **dois resultados poss√≠veis mutuamente exclusivos e exaustivos**, comumente chamados de **"sucesso"** e **"fracasso"**.

---

### Defini√ß√£o formal

Seja $X$ uma vari√°vel aleat√≥ria discreta que representa o resultado de um ensaio com dois poss√≠veis resultados:

* $X = 1$ (sucesso)
* $X = 0$ (fracasso)

A vari√°vel $X$ segue uma distribui√ß√£o de Bernoulli com par√¢metro $p$, denotada por $X \sim \text{Bernoulli}(p)$, se

$
P(X = 1) = p, \quad P(X = 0) = 1 - p
$

onde

* $p \in [0,1]$ √© a probabilidade de sucesso;
* $1-p$ √© a probabilidade de fracasso.

A fun√ß√£o de massa de probabilidade (f.p.m.) √© dada por:

$
P(X = x) = p^{x} (1-p)^{1-x}, \quad \text{para } x \in \{0,1\}
$

---

### Interpreta√ß√£o intuitiva

Imagine uma moeda que, ao ser lan√ßada, pode dar "cara" ou "coroa". Se a moeda for justa, $p = 0.5$ e ambos os resultados s√£o igualmente prov√°veis. Por√©m, se a moeda for viciada, $p \neq 0.5$, e a chance de "cara" √© diferente da chance de "coroa". Essa √© a ess√™ncia da distribui√ß√£o de Bernoulli.

Mas essa distribui√ß√£o n√£o se limita a moedas. Qualquer situa√ß√£o bin√°ria pode ser modelada por ela, como:

* Passar ou n√£o em um teste.
* Acontecimento ou n√£o de um evento (ex: um dispositivo falha ou funciona).
* Compra ou n√£o de um produto pelo consumidor.

---

### Propriedades matem√°ticas importantes

1. **Esperan√ßa (m√©dia):**

A esperan√ßa de $X$, que indica o valor m√©dio esperado de sucesso, √©

$
\mathbb{E}[X] = 1 \cdot p + 0 \cdot (1-p) = p
$

Ou seja, o valor esperado √© simplesmente a probabilidade de sucesso.

2. **Vari√¢ncia:**

A vari√¢ncia mede a dispers√£o dos valores em torno da m√©dia. Para Bernoulli:

$
\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2
$

Como $X^2 = X$ para $X \in \{0,1\}$,

$
\text{Var}(X) = p - p^2 = p(1-p)
$

Note que a vari√¢ncia √© m√°xima quando $p = 0.5$ e m√≠nima (zero) quando $p = 0$ ou $p = 1$, refletindo a certeza no resultado.

3. **Momento gerador (MGF):**

O momento gerador √© uma fun√ß√£o √∫til para calcular momentos e para caracterizar a distribui√ß√£o:

$
M_X(t) = \mathbb{E}[e^{tX}] = (1-p) + p e^{t}
$

---

### Fun√ß√£o de distribui√ß√£o acumulada (CDF)

A CDF $F(x) = P(X \leq x)$ para $X \sim \text{Bernoulli}(p)$ √©:

$
F(x) = \begin{cases}
0, & x < 0 \\
1 - p, & 0 \leq x < 1 \\
1, & x \geq 1
\end{cases}
$

Por ser discreta, a CDF tem saltos em $x=0$ e $x=1$.

---

### Rela√ß√µes e generaliza√ß√µes

* **Distribui√ß√£o Binomial:** A soma de $n$ vari√°veis aleat√≥rias independentes e identicamente distribu√≠das (i.i.d.) Bernoulli($p$) tem distribui√ß√£o Binomial($n,p$).

$
Y = \sum_{i=1}^n X_i \sim \text{Binomial}(n,p)
$

* **Distribui√ß√£o Geom√©trica:** Modela o n√∫mero de ensaios at√© o primeiro sucesso em uma sequ√™ncia de Bernoullis.

* **Distribui√ß√£o de Poisson:** Pode ser vista como um limite da distribui√ß√£o binomial para eventos raros.

---

### Exemplo detalhado

Suponha que um teste m√©dico tenha 80% de chance de detectar corretamente uma doen√ßa (sucesso). Seja $X$ a vari√°vel que indica se o teste foi positivo (1) ou negativo (0).

* $P(X=1) = 0.8$
* $P(X=0) = 0.2$

A esperan√ßa √© $\mathbb{E}[X] = 0.8$, indicando que, em m√©dia, o teste detecta a doen√ßa 80% das vezes. A vari√¢ncia √© $0.8 \times 0.2 = 0.16$, mostrando a dispers√£o do resultado em torno da m√©dia.

---

### Aplica√ß√µes pr√°ticas em ci√™ncia e tecnologia

* **Machine Learning e Estat√≠stica:**
  Classificadores bin√°rios, testes de hip√≥teses, modelos probabil√≠sticos e redes neurais usam a Bernoulli para modelar sa√≠das bin√°rias (verdadeiro/falso).

* **Engenharia de Confiabilidade:**
  Modelagem de falhas de componentes (funciona/falha).

* **Marketing e Economia:**
  An√°lise de compra vs. n√£o compra, sucesso vs. fracasso em campanhas.

* **Ci√™ncia da Computa√ß√£o:**
  Simula√ß√µes de eventos aleat√≥rios, algoritmos probabil√≠sticos.

---

### Exemplo

```python


import numpy as np

# Par√¢metro da Bernoulli
p = 0.7

# N√∫mero de lan√ßamentos
n = 10

# Simula√ß√£o dos lan√ßamentos (0 ou 1)
resultados = np.random.binomial(n=1, p=p, size=n)

# Mostrar resultados
print("Resultados dos lan√ßamentos:", resultados)
print("N√∫mero de caras (sucessos):", np.sum(resultados))
print("M√©dia amostral:", np.mean(resultados))

```

### Curiosidades e observa√ß√µes

* Embora simples, a Bernoulli √© a base para modelos probabil√≠sticos mais complexos.
* O par√¢metro $p$ pode ser interpretado como a "taxa de sucesso".
* Em infer√™ncia estat√≠stica, estimar $p$ a partir de dados Bernoulli √© um problema cl√°ssico (ex: propor√ß√£o amostral).

A **distribui√ß√£o de Bernoulli** √© o alicerce para entender processos aleat√≥rios bin√°rios. Sua simplicidade esconde uma riqueza matem√°tica e uma ampla aplicabilidade pr√°tica que permeia quase todas as √°reas da ci√™ncia e da engenharia.

Se quiser, posso mostrar c√≥digos para simula√ß√£o, exemplos de estimativa de $p$ em amostras, ou explica√ß√µes de como a Bernoulli conecta com outras distribui√ß√µes. Quer que eu fa√ßa?


### Aplica√ß√µes:

* Modelagem de ensaios bin√°rios (sucesso/fracasso).
* Fundamento da distribui√ß√£o **binomial** (soma de Bernoullis).
* Em IA, aprendizado supervisionado bin√°rio.
* Testes A/B em marketing, produ√ß√£o ou ci√™ncia de dados.

---

## üîÅ Comparando Equiprov√°vel e Bernoulli

| Caracter√≠stica             | Distribui√ß√£o Equiprov√°vel | Distribui√ß√£o de Bernoulli |
| -------------------------- | ------------------------- | ------------------------- |
| Valores poss√≠veis          | $x_1, x_2, ..., x_n$      | 0 ou 1                    |
| Probabilidades             | Iguais                    | $p$ e $1-p$               |
| Tamanho do espa√ßo amostral | $n$                       | 2                         |
| Esperan√ßa                  | $\frac{1}{n} \sum x_i$    | $p$                       |
| Vari√¢ncia                  | Depende de $x_i$          | $p(1 - p)$                |
| Uso comum                  | Jogos, sorteios           | Sucesso/fracasso bin√°rio  |

---

---

## üìù Exerc√≠cios Resolvidos

### Exerc√≠cio 1: Teste de Qualidade Industrial

**Enunciado:** Uma f√°brica de componentes eletr√¥nicos tem uma taxa de defeitos de 5% em sua produ√ß√£o. Seja $X$ a vari√°vel aleat√≥ria que indica se um componente √© defeituoso (1) ou n√£o (0). 

a) Modele essa situa√ß√£o usando uma distribui√ß√£o de Bernoulli.
b) Calcule a esperan√ßa e a vari√¢ncia de $X$.
c) Se inspecionarmos 10 componentes, qual a probabilidade de encontrarmos exatamente 2 defeituosos?

**Solu√ß√£o:**

**Parte a) Modelagem:**
Definimos a vari√°vel aleat√≥ria $X$ como:
$$X = \begin{cases}
1 & \text{se o componente √© defeituoso (sucesso)} \\
0 & \text{se o componente n√£o √© defeituoso (fracasso)}
\end{cases}$$

Como a taxa de defeitos √© 5%, temos $p = 0{,}05$.

Logo, $X \sim \text{Bernoulli}(0{,}05)$ com fun√ß√£o de probabilidade:
$$P(X = x) = 0{,}05^x \times 0{,}95^{1-x}, \quad x \in \{0,1\}$$

Especificamente:
- $P(X = 1) = 0{,}05$ (probabilidade de defeito)
- $P(X = 0) = 0{,}95$ (probabilidade de n√£o haver defeito)

**Parte b) Esperan√ßa e Vari√¢ncia:**

Esperan√ßa:
$$\mathbb{E}[X] = p = 0{,}05$$

**Interpreta√ß√£o:** Em m√©dia, 5% dos componentes s√£o defeituosos.

Vari√¢ncia:
$$\text{Var}(X) = p(1-p) = 0{,}05 \times 0{,}95 = 0{,}0475$$

**Parte c) Probabilidade com 10 componentes:**
Para 10 componentes independentes, definimos $Y = \sum_{i=1}^{10} X_i$ onde cada $X_i \sim \text{Bernoulli}(0{,}05)$.

Ent√£o $Y \sim \text{Binomial}(10, 0{,}05)$.

A probabilidade de exatamente 2 defeituosos √©:
$$P(Y = 2) = \binom{10}{2} \times 0{,}05^2 \times 0{,}95^8$$

$$P(Y = 2) = 45 \times 0{,}0025 \times 0{,}6634 = 0{,}0746$$

**Resposta:** Aproximadamente 7,46% de chance de encontrar exatamente 2 componentes defeituosos.

---

### Exerc√≠cio 2: Efic√°cia de Tratamento M√©dico

**Enunciado:** Um novo medicamento tem 80% de efic√°cia no tratamento de uma doen√ßa. Seja $X$ a vari√°vel que indica se o tratamento foi eficaz (1) ou n√£o (0) para um paciente.

a) Determine a distribui√ß√£o de $X$ e sua fun√ß√£o de probabilidade.
b) Calcule $P(X = 1)$, $\mathbb{E}[X]$ e $\text{Var}(X)$.
c) Interprete os resultados no contexto m√©dico.

**Solu√ß√£o:**

**Parte a) Distribui√ß√£o:**
$X \sim \text{Bernoulli}(0{,}8)$

Fun√ß√£o de probabilidade:
$$P(X = x) = 0{,}8^x \times 0{,}2^{1-x}, \quad x \in \{0,1\}$$

**Parte b) C√°lculos:**
- $P(X = 1) = 0{,}8$ (80% de efic√°cia)
- $P(X = 0) = 0{,}2$ (20% de falha)

Esperan√ßa:
$$\mathbb{E}[X] = 0{,}8$$

Vari√¢ncia:
$$\text{Var}(X) = 0{,}8 \times 0{,}2 = 0{,}16$$

**Parte c) Interpreta√ß√£o m√©dica:**
- O medicamento tem alta probabilidade de sucesso (80%)
- A esperan√ßa de 0,8 indica que, em m√©dia, o tratamento √© eficaz em 8 de cada 10 pacientes
- A vari√¢ncia de 0,16 mostra que h√° alguma incerteza no resultado, mas √© relativamente baixa devido √† alta efic√°cia

---

### Exerc√≠cio 3: Marketing Digital - Taxa de Convers√£o

**Enunciado:** Uma campanha de marketing digital tem taxa de convers√£o de 12%. Seja $X$ a vari√°vel que indica se um visitante do site faz uma compra (1) ou n√£o (0).

a) Modele usando Bernoulli e calcule as probabilidades.
b) Determine esperan√ßa, vari√¢ncia e desvio padr√£o.
c) Em uma amostra de 100 visitantes, quantas convers√µes esperamos?

**Solu√ß√£o:**

**Parte a) Modelagem:**
$X \sim \text{Bernoulli}(0{,}12)$

- $P(X = 1) = 0{,}12$ (convers√£o)
- $P(X = 0) = 0{,}88$ (sem convers√£o)

**Parte b) Medidas estat√≠sticas:**

Esperan√ßa:
$$\mathbb{E}[X] = 0{,}12$$

Vari√¢ncia:
$$\text{Var}(X) = 0{,}12 \times 0{,}88 = 0{,}1056$$

Desvio padr√£o:
$$\sigma = \sqrt{0{,}1056} = 0{,}325$$

**Parte c) Expectativa para 100 visitantes:**
Para $n = 100$ visitantes independentes, o n√∫mero esperado de convers√µes √©:
$$\mathbb{E}[\text{Total de convers√µes}] = n \times p = 100 \times 0{,}12 = 12 \text{ convers√µes}$$

---

### Exerc√≠cio 4: Controle de Qualidade em Software

**Enunciado:** Um sistema de detec√ß√£o de bugs identifica corretamente 95% dos erros em c√≥digos de software. Modelamos cada teste como uma vari√°vel de Bernoulli $X$.

a) Defina $X$ e determine sua distribui√ß√£o.
b) Se o sistema analisar 5 c√≥digos independentes, qual a probabilidade de detectar bugs em todos?
c) E a probabilidade de falhar na detec√ß√£o em pelo menos um c√≥digo?

**Solu√ß√£o:**

**Parte a) Defini√ß√£o:**
$$X = \begin{cases}
1 & \text{se o bug √© detectado corretamente} \\
0 & \text{se o bug n√£o √© detectado (falha)}
\end{cases}$$

$X \sim \text{Bernoulli}(0{,}95)$

**Parte b) Probabilidade de sucesso em todos os 5 c√≥digos:**
Para c√≥digos independentes, a probabilidade de sucesso em todos √©:
$$P(\text{sucesso em todos}) = P(X_1 = 1, X_2 = 1, ..., X_5 = 1)$$
$$= P(X_1 = 1) \times P(X_2 = 1) \times ... \times P(X_5 = 1)$$
$$= 0{,}95^5 = 0{,}7738$$

**Parte c) Probabilidade de pelo menos uma falha:**
$$P(\text{pelo menos uma falha}) = 1 - P(\text{nenhuma falha})$$
$$= 1 - 0{,}95^5 = 1 - 0{,}7738 = 0{,}2262$$

**Interpreta√ß√£o:** H√° cerca de 22,62% de chance de o sistema falhar na detec√ß√£o em pelo menos um dos 5 c√≥digos analisados.

---

## üéØ Exerc√≠cios Propostos

### Exerc√≠cio 1 (N√≠vel B√°sico)
Uma moeda honesta √© lan√ßada uma vez. Seja $X$ a vari√°vel aleat√≥ria que vale 1 se sair cara e 0 se sair coroa.
a) Determine a distribui√ß√£o de $X$.
b) Calcule $\mathbb{E}[X]$ e $\text{Var}(X)$.
c) Encontre $P(X = 0)$ e $P(X = 1)$.

### Exerc√≠cio 2 (N√≠vel B√°sico)
Em um teste de m√∫ltipla escolha com 4 alternativas, um aluno chuta uma quest√£o aleatoriamente. Seja $Y$ a vari√°vel que indica acerto (1) ou erro (0).
a) Modele $Y$ como uma Bernoulli.
b) Qual a probabilidade de acerto?
c) Calcule esperan√ßa e vari√¢ncia de $Y$.

### Exerc√≠cio 3 (N√≠vel Intermedi√°rio)
Uma empresa de delivery tem 8% de pedidos com atraso. Modelamos cada entrega como uma Bernoulli, onde 1 indica atraso.
a) Defina a vari√°vel aleat√≥ria e sua distribui√ß√£o.
b) Se a empresa processar 20 pedidos independentes, qual a probabilidade de todos chegarem no prazo?
c) Qual o n√∫mero esperado de atrasos em 50 entregas?

### Exerc√≠cio 4 (N√≠vel Intermedi√°rio)
Um sensor de seguran√ßa tem probabilidade de falha de 0,02 em cada opera√ß√£o. Seja $X$ a vari√°vel que indica falha (1) ou funcionamento normal (0).
a) Determine $\mathbb{E}[X]$ e $\text{Var}(X)$.
b) Em 10 opera√ß√µes independentes, qual a probabilidade de nenhuma falha?
c) Qual a probabilidade de pelo menos uma falha em 10 opera√ß√µes?

### Exerc√≠cio 5 (N√≠vel Avan√ßado)
Uma rede neural classifica imagens com 92% de acur√°cia. Considere $X$ como vari√°vel Bernoulli onde 1 indica classifica√ß√£o correta.
a) Se processarmos um batch de 100 imagens, quantas classifica√ß√µes corretas esperamos?
b) Calcule a probabilidade de acertar exatamente 90 classifica√ß√µes.
c) Determine o intervalo que cont√©m 95% das classifica√ß√µes corretas esperadas (use aproxima√ß√£o normal se necess√°rio).

### Exerc√≠cio 6 (N√≠vel Avan√ßado)
Em um estudo cl√≠nico, a taxa de cura de um tratamento experimental √© de 75%. Cada paciente pode ser modelado como uma Bernoulli independente.
a) Para uma amostra de 30 pacientes, calcule a esperan√ßa e vari√¢ncia do n√∫mero de curas.
b) Use a aproxima√ß√£o normal para estimar a probabilidade de que entre 20 e 25 pacientes sejam curados.
c) Quantos pacientes devem ser inclu√≠dos no estudo para que a probabilidade de pelo menos 80% de curas seja superior a 90%?

---

## üìò Conclus√£o

As distribui√ß√µes **equiprov√°vel** e **de Bernoulli** s√£o fundamentais para compreender experimentos aleat√≥rios discretos. Enquanto a equiprov√°vel lida com simetria (todos os resultados com mesma chance), a Bernoulli introduz **assimetria bin√°ria**, sendo essencial para aplica√ß√µes probabil√≠sticas em estat√≠stica, aprendizado de m√°quina e ci√™ncias aplicadas.

Os exerc√≠cios apresentados demonstram a versatilidade da distribui√ß√£o de Bernoulli em contextos pr√°ticos, desde controle de qualidade industrial at√© an√°lises m√©dicas e marketing digital. O dom√≠nio desses conceitos √© fundamental para avan√ßar em t√≥picos mais complexos como distribui√ß√µes binomial, geom√©trica e processos estoc√°sticos.
