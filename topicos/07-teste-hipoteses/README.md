# **Teste de Hip√≥teses: Fundamentos e Aplica√ß√µes**

O **teste de hip√≥teses** √© uma metodologia estat√≠stica fundamental para tomar decis√µes baseadas em dados. Permite avaliar se uma afirma√ß√£o (hip√≥tese) sobre uma popula√ß√£o √© suportada pela evid√™ncia dispon√≠vel em uma amostra.

## Sum√°rio

1. [Conceitos Fundamentais](#conceitos-fundamentais)
2. [Estrutura de um Teste de Hip√≥teses](#estrutura-de-um-teste-de-hip√≥teses)
3. [Fundamentos Matem√°ticos](#fundamentos-matem√°ticos)
4. [Tipos de Erro](#tipos-de-erro)
5. [Principais Testes Estat√≠sticos](#principais-testes-estat√≠sticos)
6. [Pressupostos dos Testes e Escolha Adequada](#pressupostos-dos-testes-e-escolha-adequada)
7. [Valor-p e Signific√¢ncia Estat√≠stica](#valor-p-e-signific√¢ncia-estat√≠stica)
8. [Tamanho do Efeito e Poder Estat√≠stico](#tamanho-do-efeito-e-poder-estat√≠stico)
9. [Exemplos Pr√°ticos](#exemplos-pr√°ticos)
10. [Conclus√£o](#conclus√£o)
11. [Refer√™ncias Acad√™micas](#refer√™ncias-acad√™micas)

---

## **Conceitos Fundamentais**

### **O que √© um Teste de Hip√≥teses?**

Um teste de hip√≥teses √© um procedimento estat√≠stico formal que usa dados amostrais para avaliar a plausibilidade de uma afirma√ß√£o (hip√≥tese) sobre um par√¢metro populacional. O objetivo √© determinar se h√° evid√™ncia suficiente para rejeitar uma afirma√ß√£o inicial (hip√≥tese nula) em favor de uma alternativa.

**Defini√ß√£o Formal**: Um teste de hip√≥teses √© um m√©todo inferencial que, baseado em uma amostra aleat√≥ria de tamanho *n* de uma popula√ß√£o, permite tomar decis√µes sobre afirma√ß√µes relativas aos par√¢metros populacionais (Œº, œÉ, p, etc.), controlando as probabilidades de erro.

### **Fundamentos Te√≥ricos**

O teste de hip√≥teses tem suas ra√≠zes no trabalho de pioneiros como:
- **Ronald Fisher** (anos 1920): Desenvolveu o conceito de teste de signific√¢ncia e valor-p
- **Jerzy Neyman e Egon Pearson** (anos 1930): Formalizaram a teoria dos testes de hip√≥teses com Œ± e Œ≤
- **Karl Pearson**: Contribuiu com o teste qui-quadrado e outras ferramentas fundamentais

**Paradigma Frequentista**: O teste de hip√≥teses cl√°ssico se baseia na abordagem frequentista, onde as probabilidades s√£o interpretadas como frequ√™ncias relativas de eventos em repeti√ß√µes infinitas de um experimento.

### **Por que Testar Hip√≥teses?**

- **Validar teorias**: Verificar se dados suportam teorias cient√≠ficas
- **Tomar decis√µes**: Decidir entre diferentes cursos de a√ß√£o com risco controlado
- **Controlar qualidade**: Verificar se processos atendem especifica√ß√µes t√©cnicas
- **Avaliar tratamentos**: Determinar efic√°cia de medicamentos ou interven√ß√µes
- **Infer√™ncia cient√≠fica**: Generalizar conclus√µes de amostras para popula√ß√µes

---

## **Estrutura de um Teste de Hip√≥teses**

### **1. Formula√ß√£o das Hip√≥teses**

**Hip√≥tese Nula (H‚ÇÄ)**:
- Afirma√ß√£o que assume "n√£o h√° efeito" ou "n√£o h√° diferen√ßa"
- Representa o status quo ou cren√ßa atual
- √â o que tentamos refutar

**Hip√≥tese Alternativa (H‚ÇÅ ou H‚Çê)**:
- Afirma√ß√£o que contradiz a hip√≥tese nula
- √â o que queremos demonstrar
- Pode ser unilateral ou bilateral

### **Tipos de Testes Quanto √† Direcionalidade**

**Teste Bilateral (ou bicaudal)**:
- H‚ÇÅ: Œº ‚â† Œº‚ÇÄ (a m√©dia √© diferente do valor hipot√©tico)
- Usado quando n√£o h√° expectativa pr√©via sobre a dire√ß√£o da diferen√ßa
- Regi√£o de rejei√ß√£o em ambas as caudas da distribui√ß√£o

**Teste Unilateral √† Direita**:
- H‚ÇÅ: Œº > Œº‚ÇÄ (a m√©dia √© maior que o valor hipot√©tico)
- Usado quando se espera um aumento
- Regi√£o de rejei√ß√£o na cauda direita

**Teste Unilateral √† Esquerda**:
- H‚ÇÅ: Œº < Œº‚ÇÄ (a m√©dia √© menor que o valor hipot√©tico)
- Usado quando se espera uma diminui√ß√£o
- Regi√£o de rejei√ß√£o na cauda esquerda

### **Exemplos de Formula√ß√£o**

**Exemplo 1: Teste de M√©dia (Bilateral)**
- H‚ÇÄ: Œº = 100 (a m√©dia populacional √© 100)
- H‚ÇÅ: Œº ‚â† 100 (a m√©dia populacional √© diferente de 100)

**Exemplo 2: Compara√ß√£o de Grupos**
- H‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ (as m√©dias dos dois grupos s√£o iguais)
- H‚ÇÅ: Œº‚ÇÅ ‚â† Œº‚ÇÇ (as m√©dias dos dois grupos s√£o diferentes)

**Exemplo 3: Teste Unilateral**
- H‚ÇÄ: Œº ‚â§ 10 (tempo m√©dio √© no m√°ximo 10 minutos)
- H‚ÇÅ: Œº > 10 (tempo m√©dio √© maior que 10 minutos)

### **2. Escolha do N√≠vel de Signific√¢ncia (Œ±)**

O n√≠vel de signific√¢ncia (alfa) √© a probabilidade de rejeitar H‚ÇÄ quando ela √© verdadeira:
- **Œ± = 0,05** (5%): Padr√£o mais comum
- **Œ± = 0,01** (1%): Mais conservador
- **Œ± = 0,10** (10%): Menos rigoroso

### **3. Sele√ß√£o da Estat√≠stica de Teste**

Depende do tipo de dados e hip√≥tese:
- **Teste t**: Para m√©dias com vari√¢ncia desconhecida
- **Teste Z**: Para m√©dias com vari√¢ncia conhecida
- **Teste œá¬≤**: Para independ√™ncia ou ader√™ncia
- **Teste F**: Para compara√ß√£o de vari√¢ncias

### **4. C√°lculo do Valor-p**

O valor-p √© a probabilidade de obter um resultado t√£o extremo quanto o observado, assumindo que H‚ÇÄ √© verdadeira.

### **5. Decis√£o**

- Se p-valor ‚â§ Œ±: **Rejeitamos H‚ÇÄ**
- Se p-valor > Œ±: **N√£o rejeitamos H‚ÇÄ** (ver discuss√£o detalhada na se√ß√£o [Valor-p e Signific√¢ncia Estat√≠stica](#valor-p-e-signific√¢ncia-estat√≠stica))

---

## **Fundamentos Matem√°ticos**

### **Estat√≠sticas de Teste e Suas Distribui√ß√µes**

#### **Teste Z para M√©dia (œÉ conhecido)**

Quando a vari√¢ncia populacional œÉ¬≤ √© conhecida e n √© grande (n > 30) ou os dados s√£o normais:

**Estat√≠stica de teste:**
```
Z = (XÃÑ - Œº‚ÇÄ) / (œÉ / ‚àön)
```

Onde:
- XÃÑ = m√©dia amostral
- Œº‚ÇÄ = m√©dia hipot√©tica (H‚ÇÄ)
- œÉ = desvio padr√£o populacional
- n = tamanho da amostra

Sob H‚ÇÄ, Z segue distribui√ß√£o Normal(0, 1)

**Exemplo em Python:**
```python
import numpy as np
from scipy import stats

# Dados
dados = [23, 25, 28, 22, 24, 26, 27, 25, 23, 24, 26, 25]
media_hipotetica = 25
sigma_populacional = 2  # conhecido

# C√°lculo manual
n = len(dados)
media_amostral = np.mean(dados)
z_stat = (media_amostral - media_hipotetica) / (sigma_populacional / np.sqrt(n))

# p-valor (teste bilateral)
p_valor = 2 * (1 - stats.norm.cdf(abs(z_stat)))

print(f"M√©dia amostral: {media_amostral:.4f}")
print(f"Estat√≠stica Z: {z_stat:.4f}")
print(f"p-valor: {p_valor:.4f}")
```

#### **Teste t de Student (œÉ desconhecido)**

Quando a vari√¢ncia populacional √© desconhecida (caso mais comum):

**Estat√≠stica de teste:**
```
t = (XÃÑ - Œº‚ÇÄ) / (s / ‚àön)
```

Onde:
- s = desvio padr√£o amostral
- Sob H‚ÇÄ, t segue distribui√ß√£o t de Student com (n-1) graus de liberdade

**Para duas amostras independentes:**
```
t = (XÃÑ‚ÇÅ - XÃÑ‚ÇÇ) / ‚àö(s¬≤pooled √ó (1/n‚ÇÅ + 1/n‚ÇÇ))

s¬≤pooled = ((n‚ÇÅ-1)s‚ÇÅ¬≤ + (n‚ÇÇ-1)s‚ÇÇ¬≤) / (n‚ÇÅ + n‚ÇÇ - 2)
```

**Exemplo em Python:**
```python
# Teste t para uma amostra (c√°lculo manual)
dados = [23, 25, 28, 22, 24, 26, 27, 25]
media_hipotetica = 25

n = len(dados)
media_amostral = np.mean(dados)
desvio_padrao = np.std(dados, ddof=1)  # ddof=1 para calcular desvio padr√£o amostral (divis√£o por n-1)

# Estat√≠stica t
t_stat = (media_amostral - media_hipotetica) / (desvio_padrao / np.sqrt(n))

# Graus de liberdade
df = n - 1

# p-valor (bilateral)
p_valor = 2 * (1 - stats.t.cdf(abs(t_stat), df))

print(f"Estat√≠stica t: {t_stat:.4f}")
print(f"Graus de liberdade: {df}")
print(f"p-valor: {p_valor:.4f}")

# Regi√£o cr√≠tica
alpha = 0.05
t_critico = stats.t.ppf(1 - alpha/2, df)
print(f"Valor cr√≠tico t (Œ±={alpha}): ¬±{t_critico:.4f}")

if abs(t_stat) > t_critico:
    print("Decis√£o: Rejeitar H‚ÇÄ")
else:
    print("Decis√£o: N√£o rejeitar H‚ÇÄ")
```

#### **Teste Qui-Quadrado (œá¬≤)**

**Para teste de independ√™ncia:**
```
œá¬≤ = Œ£ ((O·µ¢‚±º - E·µ¢‚±º)¬≤ / E·µ¢‚±º)
```

Onde:
- O·µ¢‚±º = frequ√™ncia observada na c√©lula (i,j)
- E·µ¢‚±º = frequ√™ncia esperada = (total linha i √ó total coluna j) / total geral
- Graus de liberdade = (linhas - 1) √ó (colunas - 1)

**Exemplo em Python:**
```python
import pandas as pd
from scipy.stats import chi2_contingency

# Tabela de conting√™ncia
tabela = np.array([[30, 10],
                   [20, 40]])

chi2_stat, p_valor, df, expected = chi2_contingency(tabela)

print("Frequ√™ncias Observadas:")
print(tabela)
print("\nFrequ√™ncias Esperadas:")
print(expected)
print(f"\nEstat√≠stica œá¬≤: {chi2_stat:.4f}")
print(f"Graus de liberdade: {df}")
print(f"p-valor: {p_valor:.4f}")

# C√°lculo manual da estat√≠stica
chi2_manual = np.sum((tabela - expected)**2 / expected)
print(f"\nœá¬≤ (c√°lculo manual): {chi2_manual:.4f}")
```

#### **Teste F (ANOVA)**

**Para ANOVA de uma via:**
```
F = MSB / MSW

MSB = Œ£n·µ¢(XÃÑ·µ¢ - XÃÑ)¬≤ / (k - 1)  (Mean Square Between groups)
MSW = Œ£(n·µ¢ - 1)s·µ¢¬≤ / (N - k)    (Mean Square Within groups)
```

Onde:
- k = n√∫mero de grupos
- N = total de observa√ß√µes
- n·µ¢ = tamanho do grupo i
- XÃÑ·µ¢ = m√©dia do grupo i
- XÃÑ = m√©dia geral

**Exemplo em Python:**
```python
# ANOVA de uma via (c√°lculo manual e usando scipy)
grupo1 = np.array([23, 25, 28, 22, 24])
grupo2 = np.array([26, 27, 29, 25, 28])
grupo3 = np.array([30, 32, 28, 31, 29])

# C√°lculo manual
todos_dados = np.concatenate([grupo1, grupo2, grupo3])
media_geral = np.mean(todos_dados)

n1, n2, n3 = len(grupo1), len(grupo2), len(grupo3)
N = n1 + n2 + n3
k = 3

# Sum of Squares Between (SSB)
ssb = (n1 * (np.mean(grupo1) - media_geral)**2 +
       n2 * (np.mean(grupo2) - media_geral)**2 +
       n3 * (np.mean(grupo3) - media_geral)**2)

# Sum of Squares Within (SSW)
ssw = (np.sum((grupo1 - np.mean(grupo1))**2) +
       np.sum((grupo2 - np.mean(grupo2))**2) +
       np.sum((grupo3 - np.mean(grupo3))**2))

# Mean Squares
msb = ssb / (k - 1)
msw = ssw / (N - k)

# Estat√≠stica F
f_stat = msb / msw

# Graus de liberdade
df_between = k - 1
df_within = N - k

# p-valor
p_valor = 1 - stats.f.cdf(f_stat, df_between, df_within)

print("=== C√ÅLCULO MANUAL ===")
print(f"SSB (Between): {ssb:.4f}")
print(f"SSW (Within): {ssw:.4f}")
print(f"MSB: {msb:.4f}")
print(f"MSW: {msw:.4f}")
print(f"Estat√≠stica F: {f_stat:.4f}")
print(f"Graus de liberdade: ({df_between}, {df_within})")
print(f"p-valor: {p_valor:.4f}")

# Compara√ß√£o com scipy
f_scipy, p_scipy = stats.f_oneway(grupo1, grupo2, grupo3)
print("\n=== SCIPY ===")
print(f"Estat√≠stica F: {f_scipy:.4f}")
print(f"p-valor: {p_scipy:.4f}")
```

### **Rela√ß√£o entre Teste de Hip√≥teses e Intervalo de Confian√ßa**

Existe uma equival√™ncia matem√°tica entre testes de hip√≥teses e intervalos de confian√ßa:

**Para teste bilateral com Œ± = 0.05:**
- Rejeitar H‚ÇÄ: Œº = Œº‚ÇÄ ‚ü∫ Œº‚ÇÄ n√£o est√° no IC 95%
- N√£o rejeitar H‚ÇÄ: Œº = Œº‚ÇÄ ‚ü∫ Œº‚ÇÄ est√° no IC 95%

**Exemplo demonstrando a equival√™ncia:**
```python
# Dados
dados = [23, 25, 28, 22, 24, 26, 27, 25, 23, 24]
media_hipotetica = 25
alpha = 0.05

# Teste t
t_stat, p_valor = stats.ttest_1samp(dados, media_hipotetica)

# Intervalo de confian√ßa
n = len(dados)
media = np.mean(dados)
se = stats.sem(dados)
df = n - 1
t_crit = stats.t.ppf(1 - alpha/2, df)
ic_inferior = media - t_crit * se
ic_superior = media + t_crit * se

print("=== TESTE DE HIP√ìTESES ===")
print(f"H‚ÇÄ: Œº = {media_hipotetica}")
print(f"p-valor: {p_valor:.4f}")
print(f"Decis√£o: {'Rejeitar H‚ÇÄ' if p_valor < alpha else 'N√£o rejeitar H‚ÇÄ'}")

print("\n=== INTERVALO DE CONFIAN√áA 95% ===")
print(f"IC: [{ic_inferior:.4f}, {ic_superior:.4f}]")
print(f"{media_hipotetica} est√° no IC? {ic_inferior <= media_hipotetica <= ic_superior}")

print("\n=== EQUIVAL√äNCIA ===")
no_ic = ic_inferior <= media_hipotetica <= ic_superior
nao_rejeita = p_valor >= alpha
print(f"Œº‚ÇÄ no IC: {no_ic}")
print(f"N√£o rejeita H‚ÇÄ: {nao_rejeita}")
print(f"Equival√™ncia verificada: {no_ic == nao_rejeita}")
```

---

## **Tipos de Erro**

### **Erro Tipo I (Œ±)**
- **Defini√ß√£o**: Rejeitar H‚ÇÄ quando ela √© verdadeira
- **Consequ√™ncia**: "Falso positivo"
- **Probabilidade**: N√≠vel de signific√¢ncia (Œ±)

### **Erro Tipo II (Œ≤)**
- **Defini√ß√£o**: N√£o rejeitar H‚ÇÄ quando ela √© falsa
- **Consequ√™ncia**: "Falso negativo"
- **Poder do teste**: 1 - Œ≤

### **Tabela de Decis√µes**

|                    | H‚ÇÄ √© Verdadeira | H‚ÇÄ √© Falsa      |
|--------------------|----------------|-----------------|
| **Rejeitamos H‚ÇÄ**  | Erro Tipo I (Œ±) | Decis√£o Correta |
| **N√£o Rejeitamos H‚ÇÄ** | Decis√£o Correta | Erro Tipo II (Œ≤) |

### **‚öñÔ∏è Balanceamento dos Erros**

- Reduzir Œ± aumenta Œ≤
- Aumentar tamanho da amostra reduz ambos os erros
- A escolha depende das consequ√™ncias de cada tipo de erro

---

## **Principais Testes Estat√≠sticos**

### **Teste t de Student**

**Aplica√ß√£o**: Testar m√©dias quando œÉ √© desconhecido

#### **Teste t para Uma Amostra**
```python
from scipy import stats
import numpy as np

# Dados de exemplo
dados = [23, 25, 28, 22, 24, 26, 27, 25, 23, 24]
media_testada = 25

# Teste t
t_stat, p_value = stats.ttest_1samp(dados, media_testada)

print(f"Estat√≠stica t: {t_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")

# Interpreta√ß√£o
alpha = 0.05
if p_value < alpha:
    print("Rejeitamos H‚ÇÄ: h√° evid√™ncia de que a m√©dia √© diferente de 25")
else:
    print("N√£o rejeitamos H‚ÇÄ: n√£o h√° evid√™ncia suficiente")
```

#### **Teste t para Duas Amostras Independentes**
```python
# Duas amostras independentes
grupo1 = [23, 25, 28, 22, 24]
grupo2 = [26, 27, 29, 25, 28]

# Teste t
t_stat, p_value = stats.ttest_ind(grupo1, grupo2)

print(f"Estat√≠stica t: {t_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")
```

### **Teste de Shapiro-Wilk (Normalidade)**

```python
# Testar normalidade dos dados
shapiro_stat, shapiro_p = stats.shapiro(dados)

print(f"Estat√≠stica de Shapiro-Wilk: {shapiro_stat:.4f}")
print(f"Valor-p: {shapiro_p:.4f}")

if shapiro_p > 0.05:
    print("Os dados seguem distribui√ß√£o normal")
else:
    print("Os dados n√£o seguem distribui√ß√£o normal")
```

### **Teste Qui-Quadrado de Independ√™ncia**

```python
import pandas as pd
from scipy.stats import chi2_contingency

# Exemplo: Rela√ß√£o entre g√™nero e prefer√™ncia de produto
dados = pd.DataFrame({
    'G√™nero': ['M', 'M', 'F', 'F', 'M', 'F', 'M', 'F', 'M', 'F'],
    'Produto': ['A', 'B', 'A', 'A', 'B', 'A', 'A', 'B', 'B', 'A']
})

# Tabela de conting√™ncia
tabela = pd.crosstab(dados['G√™nero'], dados['Produto'])
print("Tabela de Conting√™ncia:")
print(tabela)

# Teste qui-quadrado
chi2, p_value, dof, expected = chi2_contingency(tabela)

print(f"\nEstat√≠stica Qui-quadrado: {chi2:.4f}")
print(f"Valor-p: {p_value:.4f}")
print(f"Graus de liberdade: {dof}")
```

### **Teste ANOVA (An√°lise de Vari√¢ncia)**

**Aplica√ß√£o**: Comparar m√©dias de tr√™s ou mais grupos independentes

**Pressupostos**:
- Normalidade dos dados em cada grupo
- Homogeneidade de vari√¢ncias (homocedasticidade)
- Independ√™ncia das observa√ß√µes

```python
# Comparar m√©dias de m√∫ltiplos grupos
grupo1 = [23, 25, 28, 22, 24]
grupo2 = [26, 27, 29, 25, 28]
grupo3 = [30, 32, 28, 31, 29]

# ANOVA de uma via
f_stat, p_value = stats.f_oneway(grupo1, grupo2, grupo3)

print(f"Estat√≠stica F: {f_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")

if p_value < 0.05:
    print("H√° diferen√ßa significativa entre os grupos")
else:
    print("N√£o h√° diferen√ßa significativa entre os grupos")
```

### **Testes N√£o-Param√©tricos**

Testes n√£o-param√©tricos s√£o alternativas robustas quando os pressupostos dos testes param√©tricos n√£o s√£o satisfeitos. Eles n√£o assumem distribui√ß√£o espec√≠fica dos dados.

#### **Teste de Mann-Whitney U (Wilcoxon Rank-Sum)**

**Aplica√ß√£o**: Alternativa n√£o-param√©trica ao teste t para duas amostras independentes

**Quando usar**:
- Dados n√£o seguem distribui√ß√£o normal
- Vari√°veis ordinais
- Presen√ßa de outliers extremos

```python
from scipy.stats import mannwhitneyu

# Duas amostras independentes
grupo1 = [23, 25, 28, 22, 24, 100]  # Cont√©m outlier
grupo2 = [26, 27, 29, 25, 28]

# Teste de Mann-Whitney
u_stat, p_value = mannwhitneyu(grupo1, grupo2, alternative='two-sided')

print(f"Estat√≠stica U: {u_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")

if p_value < 0.05:
    print("H√° diferen√ßa significativa entre os grupos")
else:
    print("N√£o h√° diferen√ßa significativa entre os grupos")
```

#### **Teste de Wilcoxon Signed-Rank**

**Aplica√ß√£o**: Alternativa n√£o-param√©trica ao teste t pareado

**Quando usar**:
- Comparar medidas antes e depois em mesmos indiv√≠duos
- Dados n√£o normais ou ordinais

```python
from scipy.stats import wilcoxon

# Medidas antes e depois (mesmo indiv√≠duo)
antes = [85, 90, 88, 92, 87, 89, 91, 86, 90, 88]
depois = [80, 85, 83, 88, 82, 84, 87, 81, 85, 83]

# Teste de Wilcoxon
w_stat, p_value = wilcoxon(antes, depois)

print(f"Estat√≠stica W: {w_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")

if p_value < 0.05:
    print("H√° diferen√ßa significativa entre antes e depois")
else:
    print("N√£o h√° diferen√ßa significativa entre antes e depois")
```

#### **Teste de Kruskal-Wallis**

**Aplica√ß√£o**: Alternativa n√£o-param√©trica √† ANOVA de uma via

**Quando usar**:
- Comparar tr√™s ou mais grupos independentes
- Dados n√£o seguem distribui√ß√£o normal
- Presen√ßa de outliers

```python
from scipy.stats import kruskal

# Tr√™s ou mais grupos independentes
grupo1 = [23, 25, 28, 22, 24]
grupo2 = [26, 27, 29, 25, 28]
grupo3 = [30, 32, 28, 31, 29]

# Teste de Kruskal-Wallis
h_stat, p_value = kruskal(grupo1, grupo2, grupo3)

print(f"Estat√≠stica H: {h_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")

if p_value < 0.05:
    print("H√° diferen√ßa significativa entre os grupos")
else:
    print("N√£o h√° diferen√ßa significativa entre os grupos")
```

#### **Teste Exato de Fisher**

**Aplica√ß√£o**: Testar independ√™ncia em tabelas 2√ó2 com amostras pequenas

**Quando usar**:
- Tabelas de conting√™ncia 2√ó2
- Frequ√™ncias esperadas < 5 (onde qui-quadrado n√£o √© confi√°vel)

```python
from scipy.stats import fisher_exact

# Tabela de conting√™ncia 2x2
# Exemplo: Tratamento vs. Resultado
#              Sucesso  Fracasso
# Tratamento      8        2
# Controle        3        7

tabela = [[8, 2], [3, 7]]

# Teste exato de Fisher
odds_ratio, p_value = fisher_exact(tabela)

print(f"Odds Ratio: {odds_ratio:.4f}")
print(f"Valor-p: {p_value:.4f}")

if p_value < 0.05:
    print("H√° associa√ß√£o significativa entre tratamento e resultado")
else:
    print("N√£o h√° associa√ß√£o significativa")
```

### **Teste de Levene (Homogeneidade de Vari√¢ncias)**

**Aplica√ß√£o**: Verificar se dois ou mais grupos t√™m vari√¢ncias iguais

**Quando usar**:
- Antes de aplicar ANOVA ou teste t
- Verificar pressuposto de homocedasticidade

```python
from scipy.stats import levene

# Grupos para testar homogeneidade de vari√¢ncias
grupo1 = [23, 25, 28, 22, 24, 26, 27]
grupo2 = [26, 27, 29, 25, 28, 30, 31]
grupo3 = [15, 45, 10, 50, 20, 40, 25]  # Vari√¢ncia muito diferente

# Teste de Levene
w_stat, p_value = levene(grupo1, grupo2, grupo3)

print(f"Estat√≠stica W: {w_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")

if p_value < 0.05:
    print("Vari√¢ncias s√£o significativamente diferentes")
    print("Considere usar teste n√£o-param√©trico ou corre√ß√£o de Welch")
else:
    print("Vari√¢ncias s√£o homog√™neas")
```

---

## **Pressupostos dos Testes e Escolha Adequada**

### **Fluxograma de Decis√£o para Escolha de Teste**

**Para comparar dois grupos independentes:**
1. Os dados s√£o normais? (teste de Shapiro-Wilk)
   - **SIM**: Use teste t de Student
   - **N√ÉO**: Use teste de Mann-Whitney U

2. As vari√¢ncias s√£o iguais? (teste de Levene)
   - **SIM**: Use teste t padr√£o
   - **N√ÉO**: Use teste t de Welch (corre√ß√£o para vari√¢ncias desiguais)

**Para comparar dois grupos pareados:**
1. As diferen√ßas s√£o normais?
   - **SIM**: Use teste t pareado
   - **N√ÉO**: Use teste de Wilcoxon signed-rank

**Para comparar tr√™s ou mais grupos independentes:**
1. Os dados s√£o normais em todos os grupos?
   - **SIM**: Vari√¢ncias homog√™neas? ‚Üí ANOVA de uma via
   - **N√ÉO**: Use teste de Kruskal-Wallis

**Para testar associa√ß√£o entre vari√°veis categ√≥ricas:**
1. Tabela de conting√™ncia > 2√ó2 ou frequ√™ncias esperadas ‚â• 5?
   - **SIM**: Use teste qui-quadrado
   - **N√ÉO**: Use teste exato de Fisher

### **Verifica√ß√£o de Pressupostos - Exemplo Completo**

```python
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

# Dados de exemplo
np.random.seed(42)
grupo1 = np.random.normal(25, 3, 30)
grupo2 = np.random.normal(28, 3, 30)

# 1. Verificar normalidade
shapiro1 = stats.shapiro(grupo1)
shapiro2 = stats.shapiro(grupo2)

print("=== VERIFICA√á√ÉO DE NORMALIDADE ===")
print(f"Grupo 1 - Shapiro-Wilk p-value: {shapiro1.pvalue:.4f}")
print(f"Grupo 2 - Shapiro-Wilk p-value: {shapiro2.pvalue:.4f}")

normalidade_ok = shapiro1.pvalue > 0.05 and shapiro2.pvalue > 0.05

if normalidade_ok:
    print("‚úì Dados seguem distribui√ß√£o normal\n")
    
    # 2. Verificar homogeneidade de vari√¢ncias
    levene_stat, levene_p = stats.levene(grupo1, grupo2)
    print("=== VERIFICA√á√ÉO DE HOMOGENEIDADE DE VARI√ÇNCIAS ===")
    print(f"Levene p-value: {levene_p:.4f}")
    
    if levene_p > 0.05:
        print("‚úì Vari√¢ncias homog√™neas\n")
        print("=== TESTE RECOMENDADO: t de Student ===")
        t_stat, p_value = stats.ttest_ind(grupo1, grupo2)
    else:
        print("‚úó Vari√¢ncias heterog√™neas\n")
        print("=== TESTE RECOMENDADO: t de Welch ===")
        t_stat, p_value = stats.ttest_ind(grupo1, grupo2, equal_var=False)
    
    print(f"Estat√≠stica t: {t_stat:.4f}")
    print(f"Valor-p: {p_value:.4f}")
    
else:
    print("‚úó Dados n√£o seguem distribui√ß√£o normal\n")
    print("=== TESTE RECOMENDADO: Mann-Whitney U ===")
    u_stat, p_value = stats.mannwhitneyu(grupo1, grupo2)
    print(f"Estat√≠stica U: {u_stat:.4f}")
    print(f"Valor-p: {p_value:.4f}")

# Visualiza√ß√£o
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

# Histogramas
axes[0].hist(grupo1, bins=10, alpha=0.7, label='Grupo 1')
axes[0].hist(grupo2, bins=10, alpha=0.7, label='Grupo 2')
axes[0].set_xlabel('Valor')
axes[0].set_ylabel('Frequ√™ncia')
axes[0].set_title('Distribui√ß√£o dos Dados')
axes[0].legend()

# Q-Q plots
stats.probplot(grupo1, dist="norm", plot=axes[1])
axes[1].set_title('Q-Q Plot - Grupo 1')

stats.probplot(grupo2, dist="norm", plot=axes[2])
axes[2].set_title('Q-Q Plot - Grupo 2')

plt.tight_layout()
# Nota: Ajuste o caminho conforme seu sistema operacional
# Windows: 'C:\\temp\\pressupostos_teste.png'
# Linux/Mac: '/tmp/pressupostos_teste.png'
plt.savefig('pressupostos_teste.png', dpi=150, bbox_inches='tight')
print("\n‚úì Gr√°ficos de diagn√≥stico salvos em pressupostos_teste.png")
```

---

## **Valor-p e Signific√¢ncia Estat√≠stica**

### **Interpreta√ß√£o do Valor-p**

O valor-p **N√ÉO** indica:
- A probabilidade de H‚ÇÄ ser verdadeira
- O tamanho do efeito
- A import√¢ncia pr√°tica do resultado

O valor-p **INDICA**:
- A for√ßa da evid√™ncia contra H‚ÇÄ
- A probabilidade de obter resultado t√£o extremo se H‚ÇÄ fosse verdadeira

### **Interpreta√ß√£o Pr√°tica**

| Valor-p | Interpreta√ß√£o |
|---------|---------------|
| p < 0.001 | Evid√™ncia muito forte contra H‚ÇÄ |
| 0.001 ‚â§ p < 0.01 | Evid√™ncia forte contra H‚ÇÄ |
| 0.01 ‚â§ p < 0.05 | Evid√™ncia moderada contra H‚ÇÄ |
| 0.05 ‚â§ p < 0.10 | Evid√™ncia fraca contra H‚ÇÄ |
| p ‚â• 0.10 | Pouca ou nenhuma evid√™ncia contra H‚ÇÄ |

### **Corre√ß√£o para M√∫ltiplos Testes**

Quando realizamos m√∫ltiplos testes estat√≠sticos simultaneamente, a probabilidade de cometer pelo menos um erro tipo I aumenta. Isso √© conhecido como o **problema de compara√ß√µes m√∫ltiplas**.

#### **Problema de Compara√ß√µes M√∫ltiplas**

Se realizarmos *m* testes independentes, cada um com Œ± = 0.05, a probabilidade de cometer pelo menos um erro tipo I √©:

**P(pelo menos 1 erro tipo I) = 1 - (1 - Œ±)^m**

Por exemplo, com 10 testes: 1 - (0.95)^10 = 1 - 0.5987 ‚âà 0.40 (40% de chance!)

#### **Corre√ß√£o de Bonferroni**

M√©todo conservador que divide o n√≠vel de signific√¢ncia pelo n√∫mero de testes:

**Œ±_ajustado = Œ± / m**

```python
from scipy import stats
import numpy as np

# M√∫ltiplos testes de hip√≥teses
np.random.seed(42)
grupos = [np.random.normal(25, 5, 30) for _ in range(5)]

# Compara√ß√µes par a par
from itertools import combinations
p_values = []
comparacoes = []

for i, j in combinations(range(5), 2):
    t_stat, p_val = stats.ttest_ind(grupos[i], grupos[j])
    p_values.append(p_val)
    comparacoes.append(f"Grupo {i+1} vs Grupo {j+1}")

print("=== SEM CORRE√á√ÉO ===")
alpha_original = 0.05
for comp, p_val in zip(comparacoes, p_values):
    sig = "SIGNIFICATIVO" if p_val < alpha_original else "N√£o significativo"
    print(f"{comp}: p = {p_val:.4f} - {sig}")

print(f"\n=== COM CORRE√á√ÉO DE BONFERRONI ===")
m = len(p_values)  # N√∫mero de testes
alpha_bonferroni = alpha_original / m
print(f"Œ± ajustado: {alpha_bonferroni:.4f}")

for comp, p_val in zip(comparacoes, p_values):
    sig = "SIGNIFICATIVO" if p_val < alpha_bonferroni else "N√£o significativo"
    print(f"{comp}: p = {p_val:.4f} - {sig}")
```

#### **Corre√ß√£o de False Discovery Rate (FDR) - Benjamini-Hochberg**

M√©todo menos conservador que controla a propor√ß√£o de falsos positivos entre as descobertas:

```python
from statsmodels.stats.multitest import multipletests

# p-values dos testes anteriores
p_values_array = np.array(p_values)

# Aplicar corre√ß√£o FDR
reject, p_adjusted, _, _ = multipletests(p_values_array, alpha=0.05, method='fdr_bh')

print("=== CORRE√á√ÉO FDR (Benjamini-Hochberg) ===")
for comp, p_orig, p_adj, rej in zip(comparacoes, p_values, p_adjusted, reject):
    sig = "SIGNIFICATIVO" if rej else "N√£o significativo"
    print(f"{comp}")
    print(f"  p-value original: {p_orig:.4f}")
    print(f"  p-value ajustado: {p_adj:.4f}")
    print(f"  Decis√£o: {sig}\n")
```

#### **Compara√ß√£o dos M√©todos**

| M√©todo | Conservadorismo | Quando usar |
|--------|----------------|-------------|
| **Sem corre√ß√£o** | Nenhum | Apenas 1 teste |
| **Bonferroni** | Muito conservador | Poucos testes (<10), controle rigoroso |
| **FDR** | Moderado | Muitos testes, pesquisa explorat√≥ria |
| **Holm-Bonferroni** | Moderado | Alternativa √† Bonferroni |

---

## **Tamanho do Efeito e Poder Estat√≠stico**

### **Tamanho do Efeito**

Medida da magnitude pr√°tica da diferen√ßa, independente do tamanho da amostra.

#### **d de Cohen (para diferen√ßa de m√©dias)**
```python
def cohen_d(grupo1, grupo2):
    n1, n2 = len(grupo1), len(grupo2)
    s1, s2 = np.std(grupo1, ddof=1), np.std(grupo2, ddof=1)
    
    # Desvio padr√£o combinado
    s_pooled = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2))
    
    # d de Cohen
    d = (np.mean(grupo1) - np.mean(grupo2)) / s_pooled
    return d

# Exemplo
grupo1 = [23, 25, 28, 22, 24]
grupo2 = [26, 27, 29, 25, 28]

d = cohen_d(grupo1, grupo2)
print(f"d de Cohen: {d:.3f}")

# Interpreta√ß√£o
if abs(d) < 0.2:
    print("Efeito pequeno")
elif abs(d) < 0.5:
    print("Efeito m√©dio")
elif abs(d) < 0.8:
    print("Efeito grande")
else:
    print("Efeito muito grande")
```

### **C√°lculo do Poder Estat√≠stico**

```python
from statsmodels.stats import power

# Calcular poder para teste t
effect_size = 0.5  # d de Cohen
alpha = 0.05
sample_size = 30

poder = power.ttest_power(effect_size, sample_size, alpha)
print(f"Poder estat√≠stico: {poder:.3f}")

# Calcular tamanho de amostra necess√°rio
poder_desejado = 0.80
n_necessario = power.tt_solve_power(effect_size, poder_desejado, alpha)
print(f"Tamanho de amostra necess√°rio: {n_necessario:.0f}")
```

---

## **Exemplos Pr√°ticos**

### **Exemplo 1: Teste A/B em E-commerce**

**Situa√ß√£o**: Uma loja online quer testar se um novo layout aumenta a taxa de convers√£o.

```python
import numpy as np
from scipy import stats

# Dados simulados
np.random.seed(42)

# Grupo controle (layout atual)
conversoes_controle = np.random.binomial(1, 0.12, 1000)  # 12% de convers√£o
taxa_controle = np.mean(conversoes_controle)

# Grupo teste (novo layout)
conversoes_teste = np.random.binomial(1, 0.14, 1000)     # 14% de convers√£o
taxa_teste = np.mean(conversoes_teste)

print(f"Taxa de convers√£o - Controle: {taxa_controle:.3f}")
print(f"Taxa de convers√£o - Teste: {taxa_teste:.3f}")

# Teste de propor√ß√µes
from statsmodels.stats.proportion import proportions_ztest

# Contagens e totais
count = np.array([np.sum(conversoes_teste), np.sum(conversoes_controle)])
nobs = np.array([len(conversoes_teste), len(conversoes_controle)])

# Teste
z_stat, p_value = proportions_ztest(count, nobs)

print(f"\nEstat√≠stica Z: {z_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")

if p_value < 0.05:
    print("O novo layout tem efeito significativo na convers√£o!")
else:
    print("N√£o h√° evid√™ncia de melhoria significativa.")
```

### **Exemplo 2: Controle de Qualidade**

**Situa√ß√£o**: Uma f√°brica quer verificar se o peso m√©dio de seus produtos est√° dentro da especifica√ß√£o.

```python
# Dados de peso (em gramas)
pesos = [498, 502, 501, 499, 503, 500, 497, 504, 501, 499, 
         502, 498, 500, 501, 503, 499, 498, 502, 500, 501]

peso_especificado = 500  # Peso alvo

# Estat√≠sticas descritivas
print(f"Peso m√©dio observado: {np.mean(pesos):.2f}g")
print(f"Desvio padr√£o: {np.std(pesos, ddof=1):.2f}g")

# Teste t para uma amostra
t_stat, p_value = stats.ttest_1samp(pesos, peso_especificado)

print(f"\nH‚ÇÄ: Œº = {peso_especificado}g")
print(f"H‚ÇÅ: Œº ‚â† {peso_especificado}g")
print(f"Estat√≠stica t: {t_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")

alpha = 0.05
if p_value < alpha:
    print("Rejeitamos H‚ÇÄ: o peso m√©dio difere significativamente do especificado")
else:
    print("N√£o rejeitamos H‚ÇÄ: o peso m√©dio est√° conforme especifica√ß√£o")

# Intervalo de confian√ßa
from scipy.stats import t
n = len(pesos)
se = stats.sem(pesos)  # Erro padr√£o
t_crit = t.ppf(1 - alpha/2, df=n-1)
ic_inferior = np.mean(pesos) - t_crit * se
ic_superior = np.mean(pesos) + t_crit * se

print(f"\nIntervalo de confian√ßa 95%: [{ic_inferior:.2f}, {ic_superior:.2f}]g")

# Interpreta√ß√£o do IC
if peso_especificado >= ic_inferior and peso_especificado <= ic_superior:
    print(f"O valor {peso_especificado}g est√° dentro do IC 95%")
else:
    print(f"O valor {peso_especificado}g est√° FORA do IC 95%")
```

### **Exemplo 3: Teste de Normalidade e Transforma√ß√µes**

**Situa√ß√£o**: Antes de aplicar um teste t, precisamos verificar se os dados seguem distribui√ß√£o normal.

```python
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

# Dados com distribui√ß√£o assim√©trica
np.random.seed(42)
dados_assimetricos = np.random.exponential(scale=2, size=100)

# 1. Visualiza√ß√£o
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Histograma
axes[0, 0].hist(dados_assimetricos, bins=20, edgecolor='black', alpha=0.7)
axes[0, 0].set_title('Histograma - Dados Originais')
axes[0, 0].set_xlabel('Valor')
axes[0, 0].set_ylabel('Frequ√™ncia')

# Q-Q plot
stats.probplot(dados_assimetricos, dist="norm", plot=axes[0, 1])
axes[0, 1].set_title('Q-Q Plot - Dados Originais')

# 2. Teste de normalidade
shapiro_stat, shapiro_p = stats.shapiro(dados_assimetricos)
print("=== DADOS ORIGINAIS ===")
print(f"Teste de Shapiro-Wilk:")
print(f"  Estat√≠stica: {shapiro_stat:.4f}")
print(f"  p-value: {shapiro_p:.4f}")

if shapiro_p < 0.05:
    print("  Conclus√£o: Dados N√ÉO seguem distribui√ß√£o normal\n")
    
    # 3. Aplicar transforma√ß√£o logar√≠tmica
    dados_transformados = np.log(dados_assimetricos)
    
    # Visualiza√ß√£o dos dados transformados
    axes[1, 0].hist(dados_transformados, bins=20, edgecolor='black', alpha=0.7)
    axes[1, 0].set_title('Histograma - Dados Transformados (log)')
    axes[1, 0].set_xlabel('log(Valor)')
    axes[1, 0].set_ylabel('Frequ√™ncia')
    
    stats.probplot(dados_transformados, dist="norm", plot=axes[1, 1])
    axes[1, 1].set_title('Q-Q Plot - Dados Transformados (log)')
    
    # Teste de normalidade nos dados transformados
    shapiro_stat2, shapiro_p2 = stats.shapiro(dados_transformados)
    print("=== DADOS TRANSFORMADOS (logaritmo) ===")
    print(f"Teste de Shapiro-Wilk:")
    print(f"  Estat√≠stica: {shapiro_stat2:.4f}")
    print(f"  p-value: {shapiro_p2:.4f}")
    
    if shapiro_p2 > 0.05:
        print("  Conclus√£o: Dados transformados seguem distribui√ß√£o normal")
        print("  Recomenda√ß√£o: Use teste t nos dados transformados")
    else:
        print("  Conclus√£o: Mesmo transformados, dados n√£o s√£o normais")
        print("  Recomenda√ß√£o: Use teste n√£o-param√©trico")
else:
    print("  Conclus√£o: Dados seguem distribui√ß√£o normal")

plt.tight_layout()
plt.savefig('teste_normalidade.png', dpi=150, bbox_inches='tight')
print("\n‚úì Gr√°fico salvo em teste_normalidade.png")
```

### **Exemplo 4: ANOVA com Testes Post-Hoc**

**Situa√ß√£o**: Comparar efic√°cia de tr√™s diferentes tratamentos m√©dicos.

```python
import numpy as np
from scipy import stats
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import pandas as pd

# Dados simulados: tr√™s tratamentos
np.random.seed(42)
tratamento_a = np.random.normal(75, 10, 30)
tratamento_b = np.random.normal(80, 10, 30)
tratamento_c = np.random.normal(85, 10, 30)

# Combinar dados
dados = np.concatenate([tratamento_a, tratamento_b, tratamento_c])
grupos = ['A']*30 + ['B']*30 + ['C']*30

# 1. ANOVA
print("=== AN√ÅLISE DE VARI√ÇNCIA (ANOVA) ===")
f_stat, p_value = stats.f_oneway(tratamento_a, tratamento_b, tratamento_c)
print(f"Estat√≠stica F: {f_stat:.4f}")
print(f"p-value: {p_value:.4f}")

if p_value < 0.05:
    print("\nConclus√£o: H√° diferen√ßa significativa entre os grupos")
    print("Procedendo com testes post-hoc...\n")
    
    # 2. Teste de Tukey HSD (Honest Significant Difference)
    print("=== TESTE POST-HOC: Tukey HSD ===")
    tukey_result = pairwise_tukeyhsd(dados, grupos, alpha=0.05)
    print(tukey_result)
    
    # 3. Estat√≠sticas descritivas por grupo
    print("\n=== ESTAT√çSTICAS DESCRITIVAS ===")
    df = pd.DataFrame({
        'Tratamento': grupos,
        'Eficacia': dados
    })
    
    print(df.groupby('Tratamento')['Eficacia'].describe())
    
    # 4. Visualiza√ß√£o
    import matplotlib.pyplot as plt
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Boxplot
    df.boxplot(column='Eficacia', by='Tratamento', ax=axes[0])
    axes[0].set_title('Distribui√ß√£o da Efic√°cia por Tratamento')
    axes[0].set_xlabel('Tratamento')
    axes[0].set_ylabel('Efic√°cia')
    plt.sca(axes[0])
    plt.xticks([1, 2, 3], ['A', 'B', 'C'])
    
    # Gr√°fico de m√©dias com IC
    medias = df.groupby('Tratamento')['Eficacia'].mean()
    erros = df.groupby('Tratamento')['Eficacia'].sem() * 1.96  # IC 95%
    
    axes[1].bar(medias.index, medias.values, yerr=erros, capsize=10, 
                alpha=0.7, edgecolor='black')
    axes[1].set_title('M√©dias com Intervalos de Confian√ßa 95%')
    axes[1].set_xlabel('Tratamento')
    axes[1].set_ylabel('Efic√°cia M√©dia')
    axes[1].grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('anova_posthoc.png', dpi=150, bbox_inches='tight')
    print("\n‚úì Gr√°ficos salvos em anova_posthoc.png")
else:
    print("\nConclus√£o: N√£o h√° diferen√ßa significativa entre os grupos")
```

### **Exemplo 5: Teste Qui-Quadrado com An√°lise de Res√≠duos**

**Situa√ß√£o**: Analisar a associa√ß√£o entre m√©todo de ensino e aprova√ß√£o.

```python
import numpy as np
import pandas as pd
from scipy.stats import chi2_contingency

# Dados: M√©todo de ensino vs. Resultado
dados = {
    'M√©todo': ['Tradicional']*100 + ['Ativo']*100 + ['H√≠brido']*100,
    'Resultado': (['Aprovado']*60 + ['Reprovado']*40 + 
                  ['Aprovado']*75 + ['Reprovado']*25 +
                  ['Aprovado']*80 + ['Reprovado']*20)
}

df = pd.DataFrame(dados)

# Tabela de conting√™ncia
tabela = pd.crosstab(df['M√©todo'], df['Resultado'], margins=True)
print("=== TABELA DE CONTING√äNCIA ===")
print(tabela)
print()

# Tabela sem margens para o teste
tabela_teste = pd.crosstab(df['M√©todo'], df['Resultado'])

# Teste qui-quadrado
chi2, p_value, dof, expected = chi2_contingency(tabela_teste)

print("=== TESTE QUI-QUADRADO ===")
print(f"Estat√≠stica œá¬≤: {chi2:.4f}")
print(f"Graus de liberdade: {dof}")
print(f"p-value: {p_value:.4f}")

if p_value < 0.05:
    print("\nConclus√£o: H√° associa√ß√£o significativa entre m√©todo e resultado\n")
    
    # An√°lise de res√≠duos padronizados
    print("=== FREQU√äNCIAS ESPERADAS ===")
    expected_df = pd.DataFrame(expected, 
                              index=tabela_teste.index,
                              columns=tabela_teste.columns)
    print(expected_df)
    print()
    
    # Res√≠duos padronizados
    residuos = (tabela_teste - expected) / np.sqrt(expected)
    print("=== RES√çDUOS PADRONIZADOS ===")
    print("(Valores > |2| indicam contribui√ß√£o significativa para œá¬≤)")
    print(residuos)
    print()
    
    # Interpreta√ß√£o
    print("=== INTERPRETA√á√ÉO ===")
    for metodo in residuos.index:
        for resultado in residuos.columns:
            res = residuos.loc[metodo, resultado]
            if abs(res) > 2:
                direcao = "mais" if res > 0 else "menos"
                print(f"‚Ä¢ {metodo} tem {direcao} {resultado}s do que o esperado (res√≠duo: {res:.2f})")
else:
    print("\nConclus√£o: N√£o h√° associa√ß√£o significativa entre m√©todo e resultado")

# Visualiza√ß√£o
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Gr√°fico de barras agrupadas
tabela_teste.plot(kind='bar', ax=axes[0], edgecolor='black')
axes[0].set_title('Frequ√™ncias Observadas')
axes[0].set_xlabel('M√©todo de Ensino')
axes[0].set_ylabel('Frequ√™ncia')
axes[0].legend(title='Resultado')
axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)

# Heatmap de res√≠duos
im = axes[1].imshow(residuos, cmap='RdBu_r', aspect='auto', vmin=-3, vmax=3)
axes[1].set_xticks(range(len(residuos.columns)))
axes[1].set_yticks(range(len(residuos.index)))
axes[1].set_xticklabels(residuos.columns)
axes[1].set_yticklabels(residuos.index)
axes[1].set_title('Res√≠duos Padronizados')
axes[1].set_xlabel('Resultado')
axes[1].set_ylabel('M√©todo')

# Adicionar valores nos quadrados
for i in range(len(residuos.index)):
    for j in range(len(residuos.columns)):
        text = axes[1].text(j, i, f'{residuos.iloc[i, j]:.2f}',
                          ha="center", va="center", color="black")

plt.colorbar(im, ax=axes[1])
plt.tight_layout()
plt.savefig('qui_quadrado.png', dpi=150, bbox_inches='tight')
print("\n‚úì Gr√°ficos salvos em qui_quadrado.png")
```

---

## **Conclus√£o**

O teste de hip√≥teses √© uma ferramenta poderosa e fundamental para a infer√™ncia estat√≠stica e tomada de decis√µes baseada em dados. Esta metodologia, desenvolvida ao longo do s√©culo XX por estat√≠sticos pioneiros, permite quantificar a incerteza e controlar as probabilidades de erro nas decis√µes cient√≠ficas e pr√°ticas.

### **Conceitos-Chave Revisados**

1. **Dualidade de Hip√≥teses**: O teste sempre envolve H‚ÇÄ (hip√≥tese nula) e H‚ÇÅ (hip√≥tese alternativa)
2. **Controle de Erros**: Balanceamento entre erro tipo I (Œ±) e erro tipo II (Œ≤)
3. **Valor-p**: Medida de evid√™ncia contra H‚ÇÄ, n√£o a probabilidade de H‚ÇÄ ser verdadeira
4. **Pressupostos**: Cada teste tem pressupostos que devem ser verificados
5. **Alternativas Robustas**: Testes n√£o-param√©tricos quando pressupostos violados
6. **M√∫ltiplos Testes**: Necessidade de corre√ß√£o quando fazemos muitas compara√ß√µes

### **‚úÖ Boas Pr√°ticas**

**Planejamento**:
- Formule hip√≥teses **antes** de ver os dados (evitar HARKing - Formula√ß√£o de Hip√≥teses Ap√≥s Conhecer os Resultados, do ingl√™s "Hypothesizing After Results are Known")
- Defina Œ± priori baseado nas consequ√™ncias dos erros
- Calcule o tamanho amostral necess√°rio para poder adequado (1-Œ≤ ‚â• 0.80)

**Verifica√ß√£o**:
- Sempre verifique pressupostos dos testes (normalidade, homogeneidade de vari√¢ncias)
- Use gr√°ficos diagn√≥sticos (Q-Q plots, histogramas, boxplots)
- Considere testes n√£o-param√©tricos quando pressupostos violados

**Interpreta√ß√£o**:
- Reporte sempre o tamanho do efeito (d de Cohen, Œ∑¬≤, r)
- Use intervalos de confian√ßa complementando testes
- Considere signific√¢ncia pr√°tica, n√£o apenas estat√≠stica
- Seja transparente sobre m√∫ltiplos testes e corre√ß√µes aplicadas

**Comunica√ß√£o**:
- Reporte estat√≠sticas de teste, p-valores e intervalos de confian√ßa
- Descreva os pressupostos verificados
- Explique o significado pr√°tico dos resultados
- Reconhe√ßa limita√ß√µes do estudo

### **‚ö†Ô∏è Cuidados e Limita√ß√µes**

**Erros Comuns**:
- Valor-p **n√£o** indica probabilidade da hip√≥tese ser verdadeira
- Signific√¢ncia estat√≠stica **‚â†** import√¢ncia pr√°tica
- "N√£o rejeitar H‚ÇÄ" **‚â†** "aceitar H‚ÇÄ" (aus√™ncia de evid√™ncia ‚â† evid√™ncia de aus√™ncia)
- Amostras grandes podem detectar diferen√ßas triviais como "significativas"

**Problemas de Interpreta√ß√£o**:
- p = 0.049 e p = 0.051 n√£o s√£o qualitativamente diferentes
- Œ± = 0.05 √© conven√ß√£o, n√£o lei da natureza
- Um √∫nico estudo raramente √© conclusivo

**Quest√µes Metodol√≥gicas**:
- M√∫ltiplos testes aumentam probabilidade de erro tipo I
- P-hacking e cherry-picking comprometem validade
- Poder estat√≠stico baixo leva a estudos inconclusivos
- Viola√ß√£o de pressupostos pode invalidar resultados

### **üéØ Recomenda√ß√µes Avan√ßadas**

**Abordagens Complementares**:
- Combine testes de hip√≥teses com an√°lise explorat√≥ria de dados (EDA)
- Use m√©todos de reamostragem (bootstrap, permuta√ß√£o) para valida√ß√£o
- Considere m√©todos Bayesianos para infer√™ncia mais intuitiva
- Aplique meta-an√°lise para sintetizar m√∫ltiplos estudos

**Melhores Pr√°ticas Modernas**:
- Pr√©-registro de estudos para evitar vi√©s de publica√ß√£o
- Reporte de todos os testes realizados, n√£o apenas significativos
- Compartilhamento de dados e c√≥digo para reprodutibilidade
- Estima√ß√£o de incerteza com intervalos de confian√ßa

**Alternativas e Extens√µes**:
- **Infer√™ncia Bayesiana**: Incorpora conhecimento pr√©vio, mais intuitiva
- **Equivalence Testing**: Testa se diferen√ßa √© negligenci√°vel
- **Permutation Tests**: N√£o assume distribui√ß√£o param√©trica
- **Bootstrap**: Estima√ß√£o de IC quando teoria assint√≥tica n√£o se aplica

### **üìä Compara√ß√£o: Frequentista vs. Bayesiano**

| Aspecto | Frequentista | Bayesiano |
|---------|--------------|-----------|
| **Par√¢metros** | Fixos e desconhecidos | Vari√°veis aleat√≥rias |
| **Probabilidade** | Frequ√™ncia de longo prazo | Grau de cren√ßa |
| **Infer√™ncia** | p-valor, IC | Distribui√ß√£o posterior |
| **Conhecimento pr√©vio** | N√£o incorpora | Incorpora via prior |
| **Interpreta√ß√£o** | Menos intuitiva | Mais intuitiva |
| **Computa√ß√£o** | Geralmente mais simples | Pode ser intensiva |

### **üî¨ Contexto Cient√≠fico Atual**

A comunidade cient√≠fica tem debatido intensamente o uso e abuso dos testes de hip√≥teses. A American Statistical Association (ASA) publicou em 2016 uma declara√ß√£o sobre p-valores, destacando:

1. P-valores podem indicar incompatibilidade entre dados e modelo, mas n√£o medem o tamanho do efeito
2. P-valores n√£o medem a probabilidade da hip√≥tese ser verdadeira
3. Conclus√µes cient√≠ficas n√£o devem se basear apenas em cruzar um limiar de signific√¢ncia
4. Infer√™ncia apropriada requer relat√≥rio completo e transpar√™ncia

**Movimento pela Ci√™ncia Aberta**:
- Pr√©-registro de hip√≥teses e an√°lises
- Compartilhamento de dados brutos
- C√≥digo aberto para reprodutibilidade
- Relat√≥rio de todos os resultados (n√£o apenas significativos)

### **üí° Dire√ß√µes Futuras**

O campo continua evoluindo com:
- **Machine Learning**: Integra√ß√£o com m√©todos de aprendizado de m√°quina
- **Big Data**: Adapta√ß√£o para grandes volumes de dados
- **Computa√ß√£o**: M√©todos computacionalmente intensivos (MCMC, bootstrap)
- **Causalidade**: Foco em infer√™ncia causal, n√£o apenas associa√ß√£o

---

## **Refer√™ncias Acad√™micas**

### **Livros Fundamentais**

**MONTGOMERY, Douglas C.; RUNGER, George C.** *Applied Statistics and Probability for Engineers*. 7. ed. Hoboken: Wiley, 2018.
- Abordagem aplicada com foco em engenharia e ci√™ncias aplicadas

**FIELD, Andy.** *Discovering Statistics Using IBM SPSS Statistics*. 5. ed. London: SAGE Publications, 2018.
- Excelente introdu√ß√£o com humor e exemplos pr√°ticos

**COHEN, Jacob.** *Statistical Power Analysis for the Behavioral Sciences*. 2. ed. Hillsdale: Lawrence Erlbaum Associates, 1988.
- Refer√™ncia cl√°ssica sobre poder estat√≠stico e tamanho do efeito

**CASELLA, George; BERGER, Roger L.** *Statistical Inference*. 2. ed. Pacific Grove: Duxbury, 2002.
- Tratamento matem√°tico rigoroso da infer√™ncia estat√≠stica

**LEHMANN, Erich L.; ROMANO, Joseph P.** *Testing Statistical Hypotheses*. 3. ed. New York: Springer, 2005.
- Teoria completa e avan√ßada de testes de hip√≥teses

### **Artigos Importantes**

**WASSERSTEIN, Ronald L.; LAZAR, Nicole A.** The ASA Statement on p-Values: Context, Process, and Purpose. *The American Statistician*, v. 70, n. 2, p. 129-133, 2016.
- Declara√ß√£o oficial da ASA sobre uso correto de p-valores

**IOANNIDIS, John P. A.** Why Most Published Research Findings Are False. *PLOS Medicine*, v. 2, n. 8, e124, 2005.
- An√°lise cr√≠tica sobre vieses em pesquisa cient√≠fica

**COHEN, Jacob.** The Earth is Round (p < .05). *American Psychologist*, v. 49, n. 12, p. 997-1003, 1994.
- Cr√≠tica ao uso mec√¢nico de testes de signific√¢ncia

**GIGERENZER, Gerd.** Mindless Statistics. *Journal of Socio-Economics*, v. 33, n. 5, p. 587-606, 2004.
- Discuss√£o sobre interpreta√ß√£o err√¥nea de estat√≠sticas

**BENJAMIN, Daniel J. et al.** Redefine Statistical Significance. *Nature Human Behaviour*, v. 2, n. 1, p. 6-10, 2018.
- Proposta controversa de redefinir limiar de signific√¢ncia para Œ± = 0.005 (n√£o amplamente adotada)

### **Recursos Online**

**STERNE, Jonathan A. C.; SMITH, George D.** Sifting the evidence‚Äîwhat's wrong with significance tests? *BMJ*, v. 322, p. 226-231, 2001.
- Dispon√≠vel em: https://www.bmj.com/content/322/7280/226

**GOODMAN, Steven N.** Toward Evidence-Based Medical Statistics. 1: The P Value Fallacy. *Annals of Internal Medicine*, v. 130, n. 12, p. 995-1004, 1999.
- Discuss√£o sobre fal√°cias na interpreta√ß√£o de p-valores

**NUZZO, Regina.** Statistical Errors. *Nature*, v. 506, p. 150-152, 2014.
- Artigo acess√≠vel sobre erros comuns em estat√≠stica

### **Documenta√ß√£o de Software**

**SciPy Statistical Functions**: https://docs.scipy.org/doc/scipy/reference/stats.html
- Documenta√ß√£o oficial da biblioteca scipy.stats do Python

**Statsmodels**: https://www.statsmodels.org/stable/index.html
- Biblioteca Python para modelos estat√≠sticos e testes

**Pingouin**: https://pingouin-stats.org/
- Biblioteca Python moderna para estat√≠stica