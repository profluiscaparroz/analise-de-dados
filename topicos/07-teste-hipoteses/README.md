# **Teste de Hip√≥teses: Fundamentos e Aplica√ß√µes**

O **teste de hip√≥teses** √© uma metodologia estat√≠stica fundamental para tomar decis√µes baseadas em dados. Permite avaliar se uma afirma√ß√£o (hip√≥tese) sobre uma popula√ß√£o √© suportada pela evid√™ncia dispon√≠vel em uma amostra.

## Sum√°rio

1. [Conceitos Fundamentais](#conceitos-fundamentais)
2. [Estrutura de um Teste de Hip√≥teses](#estrutura-de-um-teste-de-hip√≥teses)
3. [Tipos de Erro](#tipos-de-erro)
4. [Principais Testes Estat√≠sticos](#principais-testes-estat√≠sticos)
5. [Valor-p e Signific√¢ncia Estat√≠stica](#valor-p-e-signific√¢ncia-estat√≠stica)
6. [Tamanho do Efeito e Poder Estat√≠stico](#tamanho-do-efeito-e-poder-estat√≠stico)
7. [Exemplos Pr√°ticos](#exemplos-pr√°ticos)

---

## **Conceitos Fundamentais**

### **O que √© um Teste de Hip√≥teses?**

Um teste de hip√≥teses √© um procedimento que usa dados amostrais para avaliar a plausibilidade de uma hip√≥tese sobre um par√¢metro populacional. O objetivo √© determinar se h√° evid√™ncia suficiente para rejeitar uma afirma√ß√£o inicial (hip√≥tese nula) em favor de uma alternativa.

### **Por que Testar Hip√≥teses?**

- **Validar teorias**: Verificar se dados suportam teorias cient√≠ficas
- **Tomar decis√µes**: Decidir entre diferentes cursos de a√ß√£o
- **Controlar qualidade**: Verificar se processos atendem especifica√ß√µes
- **Avaliar tratamentos**: Determinar efic√°cia de medicamentos ou interven√ß√µes

---

## **Estrutura de um Teste de Hip√≥teses**

### **1. Formula√ß√£o das Hip√≥teses**

**Hip√≥tese Nula (H‚ÇÄ)**:
- Afirma√ß√£o que assume "n√£o h√° efeito" ou "n√£o h√° diferen√ßa"
- Representa o status quo ou cren√ßa atual
- √â o que tentamos refutar

**Hip√≥tese Alternativa (H‚ÇÅ ou H‚Çê)**:
- Afirma√ß√£o que contradiz a hip√≥tese nula
- √â o que queremos demonstrar
- Pode ser unilateral ou bilateral

### **Exemplos de Formula√ß√£o**

**Exemplo 1: Teste de M√©dia**
- H‚ÇÄ: Œº = 100 (a m√©dia populacional √© 100)
- H‚ÇÅ: Œº ‚â† 100 (a m√©dia populacional √© diferente de 100)

**Exemplo 2: Compara√ß√£o de Grupos**
- H‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ (as m√©dias dos dois grupos s√£o iguais)
- H‚ÇÅ: Œº‚ÇÅ ‚â† Œº‚ÇÇ (as m√©dias dos dois grupos s√£o diferentes)

### **2. Escolha do N√≠vel de Signific√¢ncia (Œ±)**

O n√≠vel de signific√¢ncia (alfa) √© a probabilidade de rejeitar H‚ÇÄ quando ela √© verdadeira:
- **Œ± = 0,05** (5%): Padr√£o mais comum
- **Œ± = 0,01** (1%): Mais conservador
- **Œ± = 0,10** (10%): Menos rigoroso

### **3. Sele√ß√£o da Estat√≠stica de Teste**

Depende do tipo de dados e hip√≥tese:
- **Teste t**: Para m√©dias com vari√¢ncia desconhecida
- **Teste Z**: Para m√©dias com vari√¢ncia conhecida
- **Teste œá¬≤**: Para independ√™ncia ou ader√™ncia
- **Teste F**: Para compara√ß√£o de vari√¢ncias

### **4. C√°lculo do Valor-p**

O valor-p √© a probabilidade de obter um resultado t√£o extremo quanto o observado, assumindo que H‚ÇÄ √© verdadeira.

### **5. Decis√£o**

- Se p-valor ‚â§ Œ±: **Rejeitamos H‚ÇÄ**
- Se p-valor > Œ±: **N√£o rejeitamos H‚ÇÄ**

---

## **Tipos de Erro**

### **Erro Tipo I (Œ±)**
- **Defini√ß√£o**: Rejeitar H‚ÇÄ quando ela √© verdadeira
- **Consequ√™ncia**: "Falso positivo"
- **Probabilidade**: N√≠vel de signific√¢ncia (Œ±)

### **Erro Tipo II (Œ≤)**
- **Defini√ß√£o**: N√£o rejeitar H‚ÇÄ quando ela √© falsa
- **Consequ√™ncia**: "Falso negativo"
- **Poder do teste**: 1 - Œ≤

### **Tabela de Decis√µes**

|                    | H‚ÇÄ √© Verdadeira | H‚ÇÄ √© Falsa      |
|--------------------|----------------|-----------------|
| **Rejeitamos H‚ÇÄ**  | Erro Tipo I (Œ±) | Decis√£o Correta |
| **N√£o Rejeitamos H‚ÇÄ** | Decis√£o Correta | Erro Tipo II (Œ≤) |

### **‚öñÔ∏è Balanceamento dos Erros**

- Reduzir Œ± aumenta Œ≤
- Aumentar tamanho da amostra reduz ambos os erros
- A escolha depende das consequ√™ncias de cada tipo de erro

---

## **Principais Testes Estat√≠sticos**

### **Teste t de Student**

**Aplica√ß√£o**: Testar m√©dias quando œÉ √© desconhecido

#### **Teste t para Uma Amostra**
```python
from scipy import stats
import numpy as np

# Dados de exemplo
dados = [23, 25, 28, 22, 24, 26, 27, 25, 23, 24]
media_testada = 25

# Teste t
t_stat, p_value = stats.ttest_1samp(dados, media_testada)

print(f"Estat√≠stica t: {t_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")

# Interpreta√ß√£o
alpha = 0.05
if p_value < alpha:
    print("Rejeitamos H‚ÇÄ: h√° evid√™ncia de que a m√©dia √© diferente de 25")
else:
    print("N√£o rejeitamos H‚ÇÄ: n√£o h√° evid√™ncia suficiente")
```

#### **Teste t para Duas Amostras Independentes**
```python
# Duas amostras independentes
grupo1 = [23, 25, 28, 22, 24]
grupo2 = [26, 27, 29, 25, 28]

# Teste t
t_stat, p_value = stats.ttest_ind(grupo1, grupo2)

print(f"Estat√≠stica t: {t_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")
```

### **Teste de Shapiro-Wilk (Normalidade)**

```python
# Testar normalidade dos dados
shapiro_stat, shapiro_p = stats.shapiro(dados)

print(f"Estat√≠stica de Shapiro-Wilk: {shapiro_stat:.4f}")
print(f"Valor-p: {shapiro_p:.4f}")

if shapiro_p > 0.05:
    print("Os dados seguem distribui√ß√£o normal")
else:
    print("Os dados n√£o seguem distribui√ß√£o normal")
```

### **Teste Qui-Quadrado de Independ√™ncia**

```python
import pandas as pd
from scipy.stats import chi2_contingency

# Exemplo: Rela√ß√£o entre g√™nero e prefer√™ncia de produto
dados = pd.DataFrame({
    'G√™nero': ['M', 'M', 'F', 'F', 'M', 'F', 'M', 'F', 'M', 'F'],
    'Produto': ['A', 'B', 'A', 'A', 'B', 'A', 'A', 'B', 'B', 'A']
})

# Tabela de conting√™ncia
tabela = pd.crosstab(dados['G√™nero'], dados['Produto'])
print("Tabela de Conting√™ncia:")
print(tabela)

# Teste qui-quadrado
chi2, p_value, dof, expected = chi2_contingency(tabela)

print(f"\nEstat√≠stica Qui-quadrado: {chi2:.4f}")
print(f"Valor-p: {p_value:.4f}")
print(f"Graus de liberdade: {dof}")
```

### **Teste ANOVA (An√°lise de Vari√¢ncia)**

```python
# Comparar m√©dias de m√∫ltiplos grupos
grupo1 = [23, 25, 28, 22, 24]
grupo2 = [26, 27, 29, 25, 28]
grupo3 = [30, 32, 28, 31, 29]

# ANOVA de uma via
f_stat, p_value = stats.f_oneway(grupo1, grupo2, grupo3)

print(f"Estat√≠stica F: {f_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")

if p_value < 0.05:
    print("H√° diferen√ßa significativa entre os grupos")
else:
    print("N√£o h√° diferen√ßa significativa entre os grupos")
```

---

## **Valor-p e Signific√¢ncia Estat√≠stica**

### **Interpreta√ß√£o do Valor-p**

O valor-p **N√ÉO** indica:
- A probabilidade de H‚ÇÄ ser verdadeira
- O tamanho do efeito
- A import√¢ncia pr√°tica do resultado

O valor-p **INDICA**:
- A for√ßa da evid√™ncia contra H‚ÇÄ
- A probabilidade de obter resultado t√£o extremo se H‚ÇÄ fosse verdadeira

### **Interpreta√ß√£o Pr√°tica**

| Valor-p | Interpreta√ß√£o |
|---------|---------------|
| p < 0.001 | Evid√™ncia muito forte contra H‚ÇÄ |
| 0.001 ‚â§ p < 0.01 | Evid√™ncia forte contra H‚ÇÄ |
| 0.01 ‚â§ p < 0.05 | Evid√™ncia moderada contra H‚ÇÄ |
| 0.05 ‚â§ p < 0.10 | Evid√™ncia fraca contra H‚ÇÄ |
| p ‚â• 0.10 | Pouca ou nenhuma evid√™ncia contra H‚ÇÄ |

---

## **Tamanho do Efeito e Poder Estat√≠stico**

### **Tamanho do Efeito**

Medida da magnitude pr√°tica da diferen√ßa, independente do tamanho da amostra.

#### **d de Cohen (para diferen√ßa de m√©dias)**
```python
def cohen_d(grupo1, grupo2):
    n1, n2 = len(grupo1), len(grupo2)
    s1, s2 = np.std(grupo1, ddof=1), np.std(grupo2, ddof=1)
    
    # Desvio padr√£o combinado
    s_pooled = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2))
    
    # d de Cohen
    d = (np.mean(grupo1) - np.mean(grupo2)) / s_pooled
    return d

# Exemplo
grupo1 = [23, 25, 28, 22, 24]
grupo2 = [26, 27, 29, 25, 28]

d = cohen_d(grupo1, grupo2)
print(f"d de Cohen: {d:.3f}")

# Interpreta√ß√£o
if abs(d) < 0.2:
    print("Efeito pequeno")
elif abs(d) < 0.5:
    print("Efeito m√©dio")
elif abs(d) < 0.8:
    print("Efeito grande")
else:
    print("Efeito muito grande")
```

### **C√°lculo do Poder Estat√≠stico**

```python
from statsmodels.stats import power

# Calcular poder para teste t
effect_size = 0.5  # d de Cohen
alpha = 0.05
sample_size = 30

poder = power.ttest_power(effect_size, sample_size, alpha)
print(f"Poder estat√≠stico: {poder:.3f}")

# Calcular tamanho de amostra necess√°rio
poder_desejado = 0.80
n_necessario = power.tt_solve_power(effect_size, poder_desejado, alpha)
print(f"Tamanho de amostra necess√°rio: {n_necessario:.0f}")
```

---

## **Exemplos Pr√°ticos**

### **Exemplo 1: Teste A/B em E-commerce**

**Situa√ß√£o**: Uma loja online quer testar se um novo layout aumenta a taxa de convers√£o.

```python
import numpy as np
from scipy import stats

# Dados simulados
np.random.seed(42)

# Grupo controle (layout atual)
conversoes_controle = np.random.binomial(1, 0.12, 1000)  # 12% de convers√£o
taxa_controle = np.mean(conversoes_controle)

# Grupo teste (novo layout)
conversoes_teste = np.random.binomial(1, 0.14, 1000)     # 14% de convers√£o
taxa_teste = np.mean(conversoes_teste)

print(f"Taxa de convers√£o - Controle: {taxa_controle:.3f}")
print(f"Taxa de convers√£o - Teste: {taxa_teste:.3f}")

# Teste de propor√ß√µes
from statsmodels.stats.proportion import proportions_ztest

# Contagens e totais
count = np.array([np.sum(conversoes_teste), np.sum(conversoes_controle)])
nobs = np.array([len(conversoes_teste), len(conversoes_controle)])

# Teste
z_stat, p_value = proportions_ztest(count, nobs)

print(f"\nEstat√≠stica Z: {z_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")

if p_value < 0.05:
    print("O novo layout tem efeito significativo na convers√£o!")
else:
    print("N√£o h√° evid√™ncia de melhoria significativa.")
```

### **Exemplo 2: Controle de Qualidade**

**Situa√ß√£o**: Uma f√°brica quer verificar se o peso m√©dio de seus produtos est√° dentro da especifica√ß√£o.

```python
# Dados de peso (em gramas)
pesos = [498, 502, 501, 499, 503, 500, 497, 504, 501, 499, 
         502, 498, 500, 501, 503, 499, 498, 502, 500, 501]

peso_especificado = 500  # Peso alvo

# Estat√≠sticas descritivas
print(f"Peso m√©dio observado: {np.mean(pesos):.2f}g")
print(f"Desvio padr√£o: {np.std(pesos, ddof=1):.2f}g")

# Teste t para uma amostra
t_stat, p_value = stats.ttest_1samp(pesos, peso_especificado)

print(f"\nH‚ÇÄ: Œº = {peso_especificado}g")
print(f"H‚ÇÅ: Œº ‚â† {peso_especificado}g")
print(f"Estat√≠stica t: {t_stat:.4f}")
print(f"Valor-p: {p_value:.4f}")

alpha = 0.05
if p_value < alpha:
    print("Rejeitamos H‚ÇÄ: o peso m√©dio difere significativamente do especificado")
else:
    print("N√£o rejeitamos H‚ÇÄ: o peso m√©dio est√° conforme especifica√ß√£o")

# Intervalo de confian√ßa
from scipy.stats import t
n = len(pesos)
se = stats.sem(pesos)  # Erro padr√£o
t_crit = t.ppf(1 - alpha/2, df=n-1)
ic_inferior = np.mean(pesos) - t_crit * se
ic_superior = np.mean(pesos) + t_crit * se

print(f"\nIntervalo de confian√ßa 95%: [{ic_inferior:.2f}, {ic_superior:.2f}]g")
```

---

## **Conclus√£o**

O teste de hip√≥teses √© uma ferramenta poderosa para tomada de decis√µes baseada em dados. Pontos importantes:

### **‚úÖ Boas Pr√°ticas**
- Formule hip√≥teses antes de ver os dados
- Verifique pressupostos dos testes
- Reporte sempre o tamanho do efeito
- Considere signific√¢ncia pr√°tica, n√£o apenas estat√≠stica
- Use intervalos de confian√ßa complementando testes

### **‚ö†Ô∏è Cuidados**
- Valor-p n√£o indica probabilidade da hip√≥tese ser verdadeira
- Signific√¢ncia estat√≠stica ‚â† import√¢ncia pr√°tica
- M√∫ltiplos testes aumentam probabilidade de erro tipo I
- Amostras grandes podem detectar diferen√ßas triviais

### **üéØ Recomenda√ß√µes**
- Combine testes de hip√≥teses com an√°lise explorat√≥ria
- Considere m√©todos Bayesianos para problemas complexos
- Sempre avalie poder estat√≠stico e tamanho da amostra
- Documente e justifique escolhas metodol√≥gicas

---

## **Refer√™ncias**

**MONTGOMERY, Douglas C.; RUNGER, George C.** *Applied Statistics and Probability for Engineers*. 7. ed. Hoboken: Wiley, 2018.

**FIELD, Andy.** *Discovering Statistics Using IBM SPSS Statistics*. 5. ed. London: SAGE Publications, 2018.

**WASSERSTEIN, Ronald L.; LAZAR, Nicole A.** The ASA Statement on p-Values: Context, Process, and Purpose. *The American Statistician*, v. 70, n. 2, p. 129-133, 2016.

**COHEN, Jacob.** Statistical Power Analysis for the Behavioral Sciences. 2. ed. Hillsdale: Lawrence Erlbaum Associates, 1988.