# AnÃ¡lise de RegressÃ£o

## VisÃ£o Geral

Bem-vindo ao mÃ³dulo de **AnÃ¡lise de RegressÃ£o**! Este diretÃ³rio contÃ©m materiais completos e aprofundados sobre diferentes tÃ©cnicas de regressÃ£o, cada uma em sua prÃ³pria pasta com documentaÃ§Ã£o detalhada, exemplos prÃ¡ticos e cÃ³digo Python.

A anÃ¡lise de regressÃ£o Ã© uma das tÃ©cnicas estatÃ­sticas mais fundamentais e amplamente utilizadas para modelar relaÃ§Ãµes entre variÃ¡veis, fazer prediÃ§Ãµes e entender padrÃµes nos dados.

---

## ğŸ“š Estrutura do MÃ³dulo

Este mÃ³dulo estÃ¡ organizado seguindo o padrÃ£o BDD (Behavior-Driven Directory), onde cada tipo de regressÃ£o tem sua prÃ³pria pasta contendo:

- **`docs/`** - DocumentaÃ§Ã£o teÃ³rica completa em Markdown e PDF
- **`src/`** - Notebooks Jupyter com exemplos prÃ¡ticos e cÃ³digo
- **`assets/`** - Imagens, grÃ¡ficos e recursos adicionais (quando aplicÃ¡vel)

---

## ğŸ¯ TÃ³picos de RegressÃ£o

### [01. RegressÃ£o Linear Simples](./01-regressao-linear-simples/)

**O que Ã©:** Modelagem da relaÃ§Ã£o entre uma variÃ¡vel dependente e UMA variÃ¡vel independente usando uma linha reta.

**Quando usar:**
- RelaÃ§Ã£o linear entre duas variÃ¡veis
- VocÃª quer entender como X afeta Y
- PrediÃ§Ãµes simples e diretas

**Modelo matemÃ¡tico:**
```
Y = Î²â‚€ + Î²â‚X + Îµ
```

**Exemplos prÃ¡ticos:**
- ğŸ¦ Vendas de sorvete vs Temperatura
- ğŸ  PreÃ§o de imÃ³vel vs Ãrea
- ğŸ“š Nota vs Horas de estudo
- ğŸš— Consumo de combustÃ­vel vs Velocidade
- ğŸ’° SalÃ¡rio vs Anos de experiÃªncia

**O que vocÃª vai aprender:**
- MÃ©todo dos MÃ­nimos Quadrados
- InterpretaÃ§Ã£o de coeficientes
- Coeficiente de determinaÃ§Ã£o (RÂ²)
- Pressupostos do modelo
- AnÃ¡lise de resÃ­duos
- Intervalos de confianÃ§a

**NavegaÃ§Ã£o:**
- ğŸ“– [DocumentaÃ§Ã£o Completa](./01-regressao-linear-simples/docs/README.md)
- ğŸ’» [Notebook com Exemplos](./01-regressao-linear-simples/src/regressao_linear_simples_exemplos.ipynb)

---

### [02. RegressÃ£o Linear MÃºltipla](./02-regressao-linear-multipla/)

**O que Ã©:** ExtensÃ£o da regressÃ£o simples que permite modelar a relaÃ§Ã£o entre uma variÃ¡vel dependente e MÃšLTIPLAS variÃ¡veis independentes simultaneamente.

**Quando usar:**
- FenÃ´meno Ã© influenciado por vÃ¡rios fatores
- Precisa controlar variÃ¡veis confundidoras
- Quer isolar o efeito de cada variÃ¡vel
- AnÃ¡lises mais realistas

**Modelo matemÃ¡tico:**
```
Y = Î²â‚€ + Î²â‚Xâ‚ + Î²â‚‚Xâ‚‚ + ... + Î²â‚šXâ‚š + Îµ
```

**Exemplos prÃ¡ticos:**
- ğŸ˜ï¸ PreÃ§o de imÃ³veis (Ã¡rea, quartos, localizaÃ§Ã£o, idade, andar)
- ğŸ“Š Vendas (TV, rÃ¡dio, internet, preÃ§o, concorrÃªncia)
- âš¡ Consumo de energia (temperatura, pessoas, Ã¡rea, aparelhos)
- ğŸ’µ SalÃ¡rio (experiÃªncia, educaÃ§Ã£o, desempenho, cargo)
- ğŸŒ¾ Rendimento agrÃ­cola (fertilizante, Ã¡gua, temperatura, pH)

**O que vocÃª vai aprender:**
- InterpretaÃ§Ã£o de coeficientes parciais
- **Multicolinearidade** - Como detectar e tratar
- **VIF** (Variance Inflation Factor)
- SeleÃ§Ã£o de variÃ¡veis (Forward, Backward, Stepwise)
- RÂ² Ajustado
- CritÃ©rios de informaÃ§Ã£o (AIC, BIC)
- AnÃ¡lise de importÃ¢ncia relativa

**NavegaÃ§Ã£o:**
- ğŸ“– [DocumentaÃ§Ã£o Completa](./02-regressao-linear-multipla/docs/README.md)

---

### [03. RegressÃ£o Polinomial](./03-regressao-polinomial/)

**O que Ã©:** ExtensÃ£o da regressÃ£o linear para modelar relaÃ§Ãµes NÃƒO-LINEARES usando termos polinomiais (x, xÂ², xÂ³, etc.).

**Quando usar:**
- RelaÃ§Ã£o entre X e Y tem curvatura
- GrÃ¡fico de dispersÃ£o mostra padrÃ£o curvo
- ResÃ­duos da regressÃ£o linear mostram padrÃ£o
- FenÃ´menos com pontos de mÃ¡ximo/mÃ­nimo

**Modelo matemÃ¡tico:**
```
Grau 2: Y = Î²â‚€ + Î²â‚X + Î²â‚‚XÂ² + Îµ
Grau 3: Y = Î²â‚€ + Î²â‚X + Î²â‚‚XÂ² + Î²â‚ƒXÂ³ + Îµ
```

**Exemplos prÃ¡ticos:**
- ğŸš— DepreciaÃ§Ã£o de veÃ­culos (perda rÃ¡pida inicial, depois estabiliza)
- ğŸ‘· Produtividade vs Horas de trabalho (aumenta atÃ© certo ponto, depois cai)
- ğŸ“ˆ Crescimento de vendas de produto novo (curva S)
- ğŸŒ± Rendimento vs Fertilizante (aumenta atÃ© Ã³timo, depois prejudica)
- ğŸŒ¡ï¸ Vendas de sorvete vs Temperatura (pico em temp. moderada-alta)

**O que vocÃª vai aprender:**
- Escolha do grau do polinÃ´mio
- ValidaÃ§Ã£o cruzada para seleÃ§Ã£o de grau
- **Overfitting vs Underfitting**
- FenÃ´meno de Runge
- IdentificaÃ§Ã£o de pontos crÃ­ticos (mÃ¡ximos/mÃ­nimos)
- ComparaÃ§Ã£o entre diferentes graus

**NavegaÃ§Ã£o:**
- ğŸ“– [DocumentaÃ§Ã£o Completa](./03-regressao-polinomial/docs/README.md)

---

### [04. RegressÃ£o Ridge (L2 Regularization)](./04-regressao-ridge/)

**O que Ã©:** TÃ©cnica de regularizaÃ§Ã£o que adiciona penalizaÃ§Ã£o L2 (soma dos quadrados) aos coeficientes para resolver multicolinearidade e prevenir overfitting.

**Quando usar:**
- **Multicolinearidade severa** entre variÃ¡veis
- Muitas variÃ¡veis (p grande)
- p > n (mais variÃ¡veis que observaÃ§Ãµes)
- Coeficientes OLS sÃ£o instÃ¡veis
- Todas variÃ¡veis devem permanecer no modelo

**Modelo matemÃ¡tico:**
```
minimize: RSS + Î»Î£Î²â±¼Â²
```

**Exemplos prÃ¡ticos:**
- ğŸ  PreÃ§o de imÃ³veis com 50+ caracterÃ­sticas correlacionadas
- ğŸ“± Marketing com 15 canais correlacionados
- ğŸ§¬ PrevisÃ£o de doenÃ§a com 10.000 genes (p >> n)
- ğŸ“‰ PrevisÃ£o de demanda com 30 lags correlacionados
- ğŸ’¹ AnÃ¡lise econÃ´mica com indicadores macro correlacionados

**O que vocÃª vai aprender:**
- **Trade-off ViÃ©s-VariÃ¢ncia**
- Como Ridge estabiliza coeficientes
- Encolhimento de coeficientes (shrinkage)
- Escolha de Î»/Î± por validaÃ§Ã£o cruzada
- **Ridge Path** - EvoluÃ§Ã£o dos coeficientes
- PadronizaÃ§Ã£o de variÃ¡veis (crucial!)
- ComparaÃ§Ã£o com OLS

**Diferencial:**
- âœ… Estabiliza coeficientes
- âœ… Funciona com p > n
- âœ… Reduz overfitting
- âŒ NÃ£o remove variÃ¡veis (mantÃ©m todas)

**NavegaÃ§Ã£o:**
- ğŸ“– [DocumentaÃ§Ã£o Completa](./04-regressao-ridge/docs/README.md)

---

### [05. RegressÃ£o Lasso (L1 Regularization)](./05-regressao-lasso/)

**O que Ã©:** TÃ©cnica de regularizaÃ§Ã£o que adiciona penalizaÃ§Ã£o L1 (soma dos valores absolutos) e **zera coeficientes**, fazendo **seleÃ§Ã£o automÃ¡tica de variÃ¡veis**.

**Quando usar:**
- Muitas variÃ¡veis, poucas importantes
- **Precisa identificar** quais variÃ¡veis importam
- Quer modelo **simples e interpretÃ¡vel**
- SeleÃ§Ã£o de variÃ¡veis Ã© objetivo principal
- Modelo esparso Ã© desejÃ¡vel

**Modelo matemÃ¡tico:**
```
minimize: RSS + Î»Î£|Î²â±¼|
```

**Exemplos prÃ¡ticos:**
- ğŸ§¬ Identificar genes relevantes entre 10.000 (pesquisa mÃ©dica)
- ğŸ“ Selecionar palavras importantes entre 5.000 (text mining)
- ğŸ“¢ Identificar 4 canais efetivos entre 20 (marketing)
- ğŸ˜ï¸ Selecionar 18 features importantes entre 100+ (preÃ§os de imÃ³veis)
- ğŸ“Š Identificar lags relevantes entre 50 (sÃ©ries temporais)

**O que vocÃª vai aprender:**
- **SeleÃ§Ã£o automÃ¡tica de variÃ¡veis** - Principal diferencial!
- **Esparsidade** e seus benefÃ­cios
- **Lasso Path** - Como variÃ¡veis sÃ£o removidas
- Ordem de importÃ¢ncia das variÃ¡veis
- ComparaÃ§Ã£o com Ridge e OLS
- **Elastic Net** - CombinaÃ§Ã£o de L1 e L2
- Instabilidade da seleÃ§Ã£o e como lidar

**Diferencial:**
- âœ… **Seleciona variÃ¡veis** automaticamente
- âœ… Modelo esparso e interpretÃ¡vel
- âœ… Identifica fatores importantes
- âœ… Reduz custos (menos variÃ¡veis)
- âŒ Pode remover variÃ¡veis correlacionadas importantes

**NavegaÃ§Ã£o:**
- ğŸ“– [DocumentaÃ§Ã£o Completa](./05-regressao-lasso/docs/README.md)

---

## ğŸ—ºï¸ Guia de Escolha RÃ¡pida

### Diagrama de DecisÃ£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Que tipo de relaÃ§Ã£o vocÃª tem?          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚
     LINEAR              NÃƒO-LINEAR
        â”‚                    â”‚
        â”‚              â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
        â”‚              â”‚           â”‚
        â”‚         CURVATURA    COMPLEXO
        â”‚              â”‚           â”‚
        â”‚         POLINOMIAL   ML Methods
        â”‚
        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Quantas vars?  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”
    â”‚       â”‚
  UMA    MÃšLTIPLAS
    â”‚       â”‚
 SIMPLES    â”‚
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Problemas?     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                â”‚            â”‚          â”‚
   NENHUM    MULTICOLIN.    MUITAS    SELEÃ‡ÃƒO
    â”‚                â”‚            â”‚          â”‚
MÃšLTIPLA        RIDGE      RIDGE    LASSO
                                  (ou Elastic Net)
```

### Tabela Comparativa RÃ¡pida

| MÃ©todo | VariÃ¡veis | Multicolinearidade | SeleÃ§Ã£o | InterpretaÃ§Ã£o | Quando Usar |
|--------|-----------|-------------------|---------|---------------|-------------|
| **Linear Simples** | 1 | N/A | NÃ£o | â­â­â­â­â­ | RelaÃ§Ã£o linear entre 2 variÃ¡veis |
| **MÃºltipla** | MÃºltiplas | ProblemÃ¡tica | Manual | â­â­â­â­ | VÃ¡rios fatores, sem multicol. |
| **Polinomial** | 1+ | Moderada | Manual | â­â­â­ | RelaÃ§Ãµes nÃ£o-lineares com curvatura |
| **Ridge** | Muitas | Resolve | NÃ£o | â­â­ | Multicol., p>n, manter todas vars |
| **Lasso** | Muitas | Parcial | **Sim** | â­â­â­â­ | SeleÃ§Ã£o de vars, modelo esparso |

---

## ğŸ“– Como Usar Este MÃ³dulo

### 1. **Para Iniciantes - Trilha Recomendada**

```
Semana 1-2: RegressÃ£o Linear Simples
â”œâ”€ Entenda conceitos bÃ¡sicos
â”œâ”€ Domine interpretaÃ§Ã£o de coeficientes
â”œâ”€ Aprenda anÃ¡lise de resÃ­duos
â””â”€ Pratique com exemplos reais

Semana 3-4: RegressÃ£o Linear MÃºltipla
â”œâ”€ Expanda para mÃºltiplas variÃ¡veis
â”œâ”€ Aprenda multicolinearidade
â”œâ”€ Domine seleÃ§Ã£o de variÃ¡veis
â””â”€ Pratique casos complexos

Semana 5: RegressÃ£o Polinomial
â”œâ”€ Entenda relaÃ§Ãµes nÃ£o-lineares
â”œâ”€ Aprenda escolha de grau
â”œâ”€ Pratique overfitting/underfitting
â””â”€ Compare com linear

Semana 6-7: Ridge e Lasso
â”œâ”€ Entenda regularizaÃ§Ã£o
â”œâ”€ Aprenda quando usar cada um
â”œâ”€ Domine validaÃ§Ã£o cruzada
â””â”€ Pratique seleÃ§Ã£o automÃ¡tica (Lasso)
```

### 2. **Para Profissionais - ReferÃªncia RÃ¡pida**

VÃ¡ direto ao tipo de regressÃ£o que precisa:
- **PrediÃ§Ã£o simples**: Linear Simples
- **AnÃ¡lise multivariada**: MÃºltipla
- **Curvatura nos dados**: Polinomial
- **Multicolinearidade**: Ridge
- **SeleÃ§Ã£o de variÃ¡veis**: Lasso

### 3. **Para Pesquisadores**

Cada documento contÃ©m:
- âœ… FundamentaÃ§Ã£o teÃ³rica completa
- âœ… ReferÃªncias bibliogrÃ¡ficas
- âœ… FÃ³rmulas matemÃ¡ticas detalhadas
- âœ… DiscussÃ£o de pressupostos
- âœ… LimitaÃ§Ãµes e cuidados

---

## ğŸ”§ Tecnologias e Ferramentas

### Python - Bibliotecas Principais

```python
# ManipulaÃ§Ã£o de dados
import numpy as np
import pandas as pd

# VisualizaÃ§Ã£o
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import r2_score, mean_squared_error

# EstatÃ­stica
from scipy import stats
import statsmodels.api as sm
```

### Ambiente Recomendado

```bash
# Criar ambiente virtual
python -m venv venv_regressao
source venv_regressao/bin/activate  # Linux/Mac
# ou
venv_regressao\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install numpy pandas matplotlib seaborn scikit-learn scipy statsmodels jupyter
```

---

## ğŸ“Š Conceitos Transversais

### Pressupostos da RegressÃ£o Linear

Todos os mÃ©todos de regressÃ£o linear (Simples, MÃºltipla, Polinomial, Ridge, Lasso) compartilham pressupostos bÃ¡sicos:

1. **Linearidade** - RelaÃ§Ã£o linear entre X e Y (nos parÃ¢metros)
2. **IndependÃªncia** - ObservaÃ§Ãµes independentes
3. **Homocedasticidade** - VariÃ¢ncia constante dos resÃ­duos
4. **Normalidade** - ResÃ­duos seguem distribuiÃ§Ã£o normal
5. **AusÃªncia de multicolinearidade** (para mÃºltipla)

### MÃ©tricas Comuns

**RÂ² (Coeficiente de DeterminaÃ§Ã£o)**
```
RÂ² = 1 - (SSR/SST)
InterpretaÃ§Ã£o: ProporÃ§Ã£o da variabilidade explicada
```

**RMSE (Root Mean Squared Error)**
```
RMSE = âˆš(Î£(yáµ¢ - Å·áµ¢)Â²/n)
InterpretaÃ§Ã£o: Erro mÃ©dio na mesma unidade de Y
```

**MAE (Mean Absolute Error)**
```
MAE = Î£|yáµ¢ - Å·áµ¢|/n
InterpretaÃ§Ã£o: Erro mÃ©dio absoluto
```

### Workflow TÃ­pico de RegressÃ£o

```
1. AnÃ¡lise ExploratÃ³ria
   â”œâ”€ GrÃ¡ficos de dispersÃ£o
   â”œâ”€ Matriz de correlaÃ§Ã£o
   â””â”€ EstatÃ­sticas descritivas

2. PreparaÃ§Ã£o dos Dados
   â”œâ”€ Tratamento de missing values
   â”œâ”€ RemoÃ§Ã£o de outliers (se necessÃ¡rio)
   â”œâ”€ PadronizaÃ§Ã£o (Ridge/Lasso)
   â””â”€ DivisÃ£o treino/teste

3. Modelagem
   â”œâ”€ Escolha do tipo de regressÃ£o
   â”œâ”€ Ajuste do modelo
   â””â”€ OtimizaÃ§Ã£o de hiperparÃ¢metros

4. ValidaÃ§Ã£o
   â”œâ”€ MÃ©tricas de avaliaÃ§Ã£o
   â”œâ”€ AnÃ¡lise de resÃ­duos
   â””â”€ VerificaÃ§Ã£o de pressupostos

5. InterpretaÃ§Ã£o e ComunicaÃ§Ã£o
   â”œâ”€ Coeficientes
   â”œâ”€ VisualizaÃ§Ãµes
   â””â”€ Insights de negÃ³cio
```

---

## ğŸ“ Recursos Adicionais

### Livros Recomendados

1. **JAMES, Gareth et al.** *An Introduction to Statistical Learning*. 2. ed. Springer, 2021.
   - Excelente para iniciantes
   - Foco em aplicaÃ§Ãµes prÃ¡ticas
   - Exemplos em R (conceitos aplicÃ¡veis a Python)

2. **HASTIE, Trevor; TIBSHIRANI, Robert; FRIEDMAN, Jerome.** *The Elements of Statistical Learning*. 2. ed. Springer, 2009.
   - Mais avanÃ§ado
   - FundamentaÃ§Ã£o teÃ³rica profunda
   - ReferÃªncia definitiva

3. **KUTNER, Michael H. et al.** *Applied Linear Statistical Models*. 5. ed. McGraw-Hill, 2005.
   - Foco em regressÃ£o aplicada
   - Muitos exemplos prÃ¡ticos

4. **MONTGOMERY, Douglas C.; PECK, Elizabeth A.; VINING, G. Geoffrey.** *Introduction to Linear Regression Analysis*. 5. ed. Wiley, 2012.
   - Tratamento completo de regressÃ£o
   - DiagnÃ³sticos detalhados

### Cursos Online

- **Coursera**: "Machine Learning" por Andrew Ng
- **edX**: "Data Science: Linear Regression" por Harvard
- **Kaggle Learn**: "Intro to Machine Learning"
- **Khan Academy**: EstatÃ­stica e Probabilidade

### Datasets para PrÃ¡tica

- **Scikit-learn built-in**: california_housing, diabetes, fetch_openml('house_prices')
- **Kaggle**: House Prices (Ames), California Housing, Bike Sharing, etc.
- **UCI ML Repository**: VÃ¡rios datasets de regressÃ£o
- **Statsmodels**: Datasets clÃ¡ssicos de estatÃ­stica
- **Seaborn built-in**: tips, mpg, diamonds (para exemplos)

---

## ğŸ¤ Contribuindo

Este material Ã© parte do repositÃ³rio de **AnÃ¡lise de Dados** e estÃ¡ em constante evoluÃ§Ã£o.

### Como Contribuir

1. Relate erros ou sugestÃµes via Issues
2. Proponha melhorias via Pull Requests
3. Adicione exemplos prÃ¡ticos
4. Melhore a documentaÃ§Ã£o
5. Traduza para outros idiomas

### PadrÃ£o de Qualidade

Ao contribuir, mantenha:
- âœ… ExplicaÃ§Ãµes claras e didÃ¡ticas
- âœ… Exemplos prÃ¡ticos do dia a dia
- âœ… CÃ³digo comentado e executÃ¡vel
- âœ… ReferÃªncias bibliogrÃ¡ficas
- âœ… FormataÃ§Ã£o consistente

---

## ğŸ“œ LicenÃ§a

Este material Ã© disponibilizado sob licenÃ§a MIT. Veja o arquivo LICENSE no repositÃ³rio principal para mais detalhes.

---

## ğŸ“§ Contato e Suporte

Para dÃºvidas, sugestÃµes ou discussÃµes:
- **Issues**: Use o sistema de Issues do GitHub
- **DiscussÃµes**: Use GitHub Discussions
- **Email**: Via perfil do GitHub

---

## ğŸ¯ PrÃ³ximos Passos Recomendados

ApÃ³s dominar regressÃ£o linear, explore:

### Modelos Relacionados
- **RegressÃ£o LogÃ­stica** - Para variÃ¡veis categÃ³ricas
- **GLM** (Generalized Linear Models) - ExtensÃ£o para distribuiÃ§Ãµes nÃ£o-normais
- **GAM** (Generalized Additive Models) - RelaÃ§Ãµes nÃ£o-lineares mais flexÃ­veis
- **Modelos de SÃ©ries Temporais** - ARIMA, SARIMA, etc.

### Machine Learning
- **Ãrvores de DecisÃ£o e Random Forests**
- **Gradient Boosting** (XGBoost, LightGBM, CatBoost)
- **Redes Neurais** para regressÃ£o
- **Support Vector Regression (SVR)**

### EstatÃ­stica AvanÃ§ada
- **RegressÃ£o NÃ£o-ParamÃ©trica**
- **Modelos HierÃ¡rquicos/MultinÃ­vel**
- **RegressÃ£o QuantÃ­lica**
- **Modelos Bayesianos**

---

## ğŸ“š GlossÃ¡rio RÃ¡pido

| Termo | Significado |
|-------|-------------|
| **VariÃ¡vel Dependente (Y)** | VariÃ¡vel que queremos prever/explicar |
| **VariÃ¡vel Independente (X)** | VariÃ¡vel(is) que usamos para prever Y |
| **Coeficiente (Î²)** | ParÃ¢metro que quantifica relaÃ§Ã£o entre X e Y |
| **Intercepto (Î²â‚€)** | Valor de Y quando X=0 |
| **ResÃ­duo** | DiferenÃ§a entre valor real e predito |
| **RÂ²** | ProporÃ§Ã£o da variabilidade explicada (0-1) |
| **RMSE** | Raiz do erro quadrÃ¡tico mÃ©dio |
| **Multicolinearidade** | CorrelaÃ§Ã£o entre variÃ¡veis independentes |
| **Overfitting** | Modelo muito complexo, memoriza treino |
| **RegularizaÃ§Ã£o** | TÃ©cnica para reduzir overfitting |
| **Esparsidade** | Muitos coeficientes sÃ£o zero (Lasso) |
| **ValidaÃ§Ã£o Cruzada** | TÃ©cnica para avaliar generalizaÃ§Ã£o |

---

## âœ… Checklist de Aprendizado

Use este checklist para acompanhar seu progresso:

### RegressÃ£o Linear Simples
- [ ] Entendo o conceito de relaÃ§Ã£o linear
- [ ] Sei interpretar coeficientes (Î²â‚€, Î²â‚)
- [ ] Sei calcular e interpretar RÂ²
- [ ] Sei fazer anÃ¡lise de resÃ­duos
- [ ] Entendo pressupostos do modelo
- [ ] Consigo implementar em Python

### RegressÃ£o Linear MÃºltipla
- [ ] Entendo conceito de coeficientes parciais
- [ ] Sei detectar multicolinearidade (VIF)
- [ ] ConheÃ§o mÃ©todos de seleÃ§Ã£o de variÃ¡veis
- [ ] Sei usar RÂ² ajustado
- [ ] Consigo interpretar modelo com mÃºltiplas variÃ¡veis

### RegressÃ£o Polinomial
- [ ] Entendo quando usar polinomial vs linear
- [ ] Sei escolher grau do polinÃ´mio
- [ ] Entendo overfitting vs underfitting
- [ ] Sei identificar pontos crÃ­ticos

### Ridge Regression
- [ ] Entendo conceito de regularizaÃ§Ã£o L2
- [ ] Sei quando usar Ridge
- [ ] Entendo trade-off viÃ©s-variÃ¢ncia
- [ ] Sei escolher Î± por validaÃ§Ã£o cruzada
- [ ] Lembro de padronizar variÃ¡veis

### Lasso Regression
- [ ] Entendo conceito de regularizaÃ§Ã£o L1
- [ ] Entendo seleÃ§Ã£o automÃ¡tica de variÃ¡veis
- [ ] Sei interpretar Lasso Path
- [ ] Sei quando usar Lasso vs Ridge
- [ ] ConheÃ§o Elastic Net

---

## ğŸ‰ ConclusÃ£o

Este mÃ³dulo oferece uma cobertura completa de tÃ©cnicas de regressÃ£o, desde os fundamentos atÃ© mÃ©todos avanÃ§ados de regularizaÃ§Ã£o. Cada tÃ³pico foi desenvolvido com:

âœ¨ **Teoria sÃ³lida** - FundamentaÃ§Ã£o matemÃ¡tica e estatÃ­stica  
âœ¨ **Exemplos prÃ¡ticos** - Casos reais do dia a dia  
âœ¨ **CÃ³digo funcional** - ImplementaÃ§Ãµes completas em Python  
âœ¨ **VisualizaÃ§Ãµes** - GrÃ¡ficos para melhor compreensÃ£o  
âœ¨ **Boas prÃ¡ticas** - Workflow profissional

**Boa jornada de aprendizado! ğŸ“ˆğŸš€**

---

*Ãšltima atualizaÃ§Ã£o: Janeiro de 2026*  
*RepositÃ³rio: AnÃ¡lise de Dados - Prof. Luis Caparroz*
