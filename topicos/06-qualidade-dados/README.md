# **Qualidade de Dados: Fundamentos e Metodologias de Valida√ß√£o**

A **qualidade de dados** √© um aspecto fundamental na an√°lise de dados que determina a confiabilidade, precis√£o e utilidade dos insights extra√≠dos. Dados de baixa qualidade podem levar a conclus√µes incorretas e decis√µes prejudiciais para organiza√ß√µes e projetos.

## Sum√°rio

1. [O que √© Qualidade de Dados](#o-que-√©-qualidade-de-dados)
2. [Dimens√µes da Qualidade de Dados](#dimens√µes-da-qualidade-de-dados)
3. [Problemas Comuns de Qualidade](#problemas-comuns-de-qualidade)
4. [T√©cnicas de Valida√ß√£o de Dados](#t√©cnicas-de-valida√ß√£o-de-dados)
5. [Processo de Limpeza de Dados](#processo-de-limpeza-de-dados)
6. [Ferramentas e Metodologias](#ferramentas-e-metodologias)
7. [Exemplos Pr√°ticos](#exemplos-pr√°ticos)

---

## **O que √© Qualidade de Dados**

Qualidade de dados refere-se ao grau em que os dados atendem aos requisitos para seu uso pretendido. Dados de alta qualidade s√£o:

- **Precisos**: Refletem corretamente a realidade
- **Completos**: Cont√™m todas as informa√ß√µes necess√°rias
- **Consistentes**: N√£o cont√™m contradi√ß√µes
- **Confi√°veis**: Podem ser utilizados com seguran√ßa para tomada de decis√µes
- **Atualizados**: Representam o estado atual das informa√ß√µes

### üìä **Impacto da Qualidade dos Dados**

Segundo estudos da IBM, dados de baixa qualidade custam √† economia americana aproximadamente **3,1 trilh√µes de d√≥lares por ano**. Os impactos incluem:

- Decis√µes incorretas baseadas em informa√ß√µes imprecisas
- Perda de confian√ßa do cliente
- Inefici√™ncias operacionais
- Custos adicionais de corre√ß√£o
- Riscos de conformidade regulat√≥ria

---

## **Dimens√µes da Qualidade de Dados**

### **1. Precis√£o (Accuracy)**
Os dados representam corretamente o objeto ou evento real.

**Exemplo**: Um cliente cadastrado com idade de 150 anos indica problema de precis√£o.

### **2. Completude (Completeness)**
Todos os dados necess√°rios est√£o presentes.

**Exemplo**: Tabela de vendas onde 30% dos registros n√£o t√™m informa√ß√£o de regi√£o.

### **3. Consist√™ncia (Consistency)**
Os dados n√£o cont√™m contradi√ß√µes internas ou com outras fontes.

**Exemplo**: Cliente com data de nascimento posterior √† data de primeiro pedido.

### **4. Integridade (Integrity)**
Os dados seguem regras de neg√≥cio e restri√ß√µes definidas.

**Exemplo**: C√≥digo de produto que n√£o existe na tabela de produtos.

### **5. Validade (Validity)**
Os dados seguem formatos e regras sint√°ticas definidas.

**Exemplo**: Campo de email com valor "abc123" ao inv√©s de um email v√°lido.

### **6. Atualidade (Timeliness)**
Os dados s√£o atuais e relevantes para o momento de uso.

**Exemplo**: Pre√ßos de produtos que n√£o foram atualizados h√° meses.

### **7. Unicidade (Uniqueness)**
N√£o h√° duplica√ß√£o desnecess√°ria de dados.

**Exemplo**: Mesmo cliente cadastrado m√∫ltiplas vezes com grafias ligeiramente diferentes.

---

## **Problemas Comuns de Qualidade**

### **üî¥ Dados Ausentes (Missing Data)**

**Tipos de dados ausentes**:
- **MCAR** (Missing Completely at Random): Aus√™ncia aleat√≥ria
- **MAR** (Missing at Random): Aus√™ncia relacionada a outras vari√°veis observadas
- **NMAR** (Not Missing at Random): Aus√™ncia relacionada ao pr√≥prio valor n√£o observado

**Estrat√©gias de tratamento**:
- Remo√ß√£o de registros incompletos
- Imputa√ß√£o com m√©dia/mediana/moda
- Imputa√ß√£o m√∫ltipla
- Algoritmos espec√≠ficos para dados ausentes

### **üî¥ Outliers e Valores An√¥malos**

**Identifica√ß√£o**:
- An√°lise visual (box plots, histogramas)
- Regra do IQR (Intervalo Interquartil)
- Z-score (valores > 3 desvios padr√£o)
- M√©todos estat√≠sticos avan√ßados

**Tratamento**:
- Remo√ß√£o (se confirmadamente erro)
- Transforma√ß√£o (log, raiz quadrada)
- Winsoriza√ß√£o (substitui√ß√£o por percentis)
- Manuten√ß√£o (se representam fen√¥menos reais)

### **üî¥ Inconsist√™ncias e Duplicatas**

**Exemplos comuns**:
- Varia√ß√µes na grafia de nomes
- Diferentes formatos de data/hora
- Unidades de medida inconsistentes
- Registros duplicados com pequenas varia√ß√µes

---

## **T√©cnicas de Valida√ß√£o de Dados**

### **1. Valida√ß√£o Sint√°tica**
Verifica se os dados seguem formatos esperados.

```python
import re

def validar_email(email):
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return bool(re.match(pattern, email))

def validar_cpf(cpf):
    # Remove caracteres n√£o num√©ricos
    cpf = re.sub(r'[^0-9]', '', cpf)
    return len(cpf) == 11 and not cpf == cpf[0] * 11
```

### **2. Valida√ß√£o Sem√¢ntica**
Verifica se os dados fazem sentido no contexto.

```python
from datetime import datetime, date

def validar_idade(data_nascimento):
    hoje = date.today()
    idade = hoje.year - data_nascimento.year
    return 0 <= idade <= 120

def validar_salario(salario, cargo):
    # Faixas salariais por cargo
    faixas = {
        'estagiario': (800, 2000),
        'junior': (2000, 5000),
        'senior': (5000, 15000),
        'gerente': (8000, 25000)
    }
    
    if cargo.lower() in faixas:
        min_sal, max_sal = faixas[cargo.lower()]
        return min_sal <= salario <= max_sal
    return True  # Se cargo n√£o conhecido, aceita
```

### **3. Valida√ß√£o de Refer√™ncias**
Verifica integridade referencial entre tabelas.

```python
def validar_integridade_referencial(df_vendas, df_produtos):
    # Verifica se todos os produtos em vendas existem na tabela de produtos
    produtos_invalidos = df_vendas[
        ~df_vendas['produto_id'].isin(df_produtos['id'])
    ]
    return len(produtos_invalidos) == 0, produtos_invalidos
```

---

## **Processo de Limpeza de Dados**

### **Etapa 1: Profiling dos Dados**
An√°lise inicial para entender a estrutura e qualidade.

```python
import pandas as pd
import numpy as np

def profile_dataframe(df):
    print("=== PROFILING DE DADOS ===")
    print(f"Dimens√µes: {df.shape}")
    print(f"\nTipos de dados:")
    print(df.dtypes)
    print(f"\nValores ausentes:")
    print(df.isnull().sum())
    print(f"\nValores √∫nicos por coluna:")
    print(df.nunique())
    print(f"\nEstat√≠sticas descritivas:")
    print(df.describe())
```

### **Etapa 2: Identifica√ß√£o de Problemas**

```python
def identificar_problemas(df):
    problemas = []
    
    # Verificar dados ausentes
    colunas_com_nulos = df.columns[df.isnull().any()].tolist()
    if colunas_com_nulos:
        problemas.append(f"Colunas com valores ausentes: {colunas_com_nulos}")
    
    # Verificar duplicatas
    duplicatas = df.duplicated().sum()
    if duplicatas > 0:
        problemas.append(f"Registros duplicados: {duplicatas}")
    
    # Verificar outliers (para colunas num√©ricas)
    for col in df.select_dtypes(include=[np.number]).columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        outliers = df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)][col].count()
        if outliers > 0:
            problemas.append(f"Outliers em {col}: {outliers}")
    
    return problemas
```

### **Etapa 3: Corre√ß√£o e Limpeza**

```python
def limpar_dados(df):
    df_limpo = df.copy()
    
    # Remover duplicatas
    df_limpo = df_limpo.drop_duplicates()
    
    # Padronizar texto
    for col in df_limpo.select_dtypes(include=['object']).columns:
        df_limpo[col] = df_limpo[col].astype(str).str.strip().str.lower()
    
    # Tratar valores ausentes
    for col in df_limpo.columns:
        if df_limpo[col].dtype in ['int64', 'float64']:
            # Para num√©ricos: preencher com mediana
            df_limpo[col].fillna(df_limpo[col].median(), inplace=True)
        else:
            # Para categ√≥ricos: preencher com moda
            df_limpo[col].fillna(df_limpo[col].mode()[0] if not df_limpo[col].mode().empty else 'N/A', inplace=True)
    
    return df_limpo
```

---

## **Ferramentas e Metodologias**

### **Ferramentas Open Source**
- **pandas (Python)**: Manipula√ß√£o e limpeza de dados
- **Great Expectations (Python)**: Framework para valida√ß√£o de dados
- **Deequ (Scala/Python)**: Biblioteca da Amazon para qualidade de dados
- **OpenRefine**: Ferramenta visual para limpeza de dados

### **Ferramentas Comerciais**
- **Talend Data Quality**: Plataforma completa de qualidade de dados
- **IBM InfoSphere QualityStage**: Solu√ß√£o enterprise
- **Microsoft Data Quality Services**: Integrado ao SQL Server
- **Dataiku**: Plataforma de ci√™ncia de dados com foco em qualidade

### **Metodologias**
- **TDQM** (Total Data Quality Management): Abordagem hol√≠stica
- **DAMA-DMBOK**: Framework de gest√£o de dados
- **ISO 8000**: Padr√£o internacional para qualidade de dados

---

## **Exemplos Pr√°ticos**

### **Exemplo 1: Valida√ß√£o de Dataset de Vendas**

```python
import pandas as pd
from datetime import datetime

# Carregar dados
df_vendas = pd.read_csv('vendas.csv')

# Fun√ß√µes de valida√ß√£o
def validar_vendas(df):
    erros = []
    
    # Validar se valor_venda √© positivo
    if (df['valor_venda'] <= 0).any():
        erros.append("Encontrados valores de venda negativos ou zero")
    
    # Validar se data_venda n√£o √© futura
    df['data_venda'] = pd.to_datetime(df['data_venda'])
    if (df['data_venda'] > datetime.now()).any():
        erros.append("Encontradas datas de venda futuras")
    
    # Validar se quantidade √© inteira e positiva
    if (df['quantidade'] <= 0).any() or (df['quantidade'] != df['quantidade'].astype(int)).any():
        erros.append("Quantidades inv√°lidas encontradas")
    
    return erros

# Executar valida√ß√£o
erros_encontrados = validar_vendas(df_vendas)
for erro in erros_encontrados:
    print(f"‚ùå {erro}")
```

### **Exemplo 2: Detec√ß√£o de Duplicatas Inteligente**

```python
from fuzzywuzzy import fuzz

def detectar_duplicatas_fuzzy(df, coluna_nome, threshold=85):
    """Detecta duplicatas usando similaridade de strings"""
    duplicatas_potenciais = []
    
    for i, nome1 in enumerate(df[coluna_nome]):
        for j, nome2 in enumerate(df[coluna_nome]):
            if i < j:  # Evitar comparar o mesmo registro
                similaridade = fuzz.ratio(str(nome1).lower(), str(nome2).lower())
                if similaridade >= threshold:
                    duplicatas_potenciais.append({
                        'index1': i,
                        'index2': j,
                        'nome1': nome1,
                        'nome2': nome2,
                        'similaridade': similaridade
                    })
    
    return duplicatas_potenciais

# Exemplo de uso
df_clientes = pd.DataFrame({
    'nome': ['Jo√£o Silva', 'Joao Silva', 'Maria Santos', 'Pedro Oliveira']
})

duplicatas = detectar_duplicatas_fuzzy(df_clientes, 'nome')
for dup in duplicatas:
    print(f"Poss√≠vel duplicata: '{dup['nome1']}' vs '{dup['nome2']}' (Similaridade: {dup['similaridade']}%)")
```

---

## **Conclus√£o**

A qualidade de dados √© fundamental para o sucesso de qualquer projeto de an√°lise de dados. Um processo bem estruturado de valida√ß√£o e limpeza de dados deve incluir:

1. **Avalia√ß√£o inicial** dos dados (profiling)
2. **Identifica√ß√£o** de problemas de qualidade
3. **Implementa√ß√£o** de regras de valida√ß√£o
4. **Corre√ß√£o** de problemas identificados
5. **Monitoramento** cont√≠nuo da qualidade

**Princ√≠pios importantes**:
- **Preven√ß√£o √© melhor que corre√ß√£o**: Implemente valida√ß√µes na entrada de dados
- **Documente tudo**: Mantenha registro das regras de limpeza aplicadas
- **Mantenha dados originais**: Sempre preserve uma c√≥pia dos dados brutos
- **Monitore continuamente**: A qualidade de dados √© um processo, n√£o um evento √∫nico

Investir em qualidade de dados √© investir na confiabilidade e valor dos insights gerados pela an√°lise de dados.

---

## **Refer√™ncias**

**REDMAN, Thomas C.** *Data Driven: Creating a Data Culture*. Boston: Harvard Business Review Press, 2020.

**LOSHIN, David.** *Master Data Management*. Burlington: Morgan Kaufmann, 2009.

**SEBASTIAN-COLEMAN, Laura.** *Measuring Data Quality for Ongoing Improvement*. Burlington: Morgan Kaufmann, 2012.

**WANG, Richard Y.; STRONG, Diane M.** Beyond Accuracy: What Data Quality Means to Data Consumers. *Journal of Management Information Systems*, v. 12, n. 4, p. 5-33, 1996.