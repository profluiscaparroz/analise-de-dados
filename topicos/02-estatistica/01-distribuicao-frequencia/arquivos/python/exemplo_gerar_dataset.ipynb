{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Geração de dataset"
      ],
      "metadata": {
        "id": "Us_9At6lvJgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **O que é um Dataset e por que criá-lo?**  \n",
        "\n",
        "Um **dataset** (ou conjunto de dados) é uma coleção organizada de informações estruturadas que representam um determinado fenômeno ou contexto. Ele pode conter dados numéricos, textuais, categóricos ou até multimídia, armazenados em formatos como **CSV, JSON, SQL, entre outros**.  \n",
        "\n",
        "Criar um dataset é essencial para diversas aplicações, como **ciência de dados, aprendizado de máquina, estatísticas e análises empresariais**, pois permite que informações sejam armazenadas, manipuladas e analisadas para extrair insights valiosos.  \n",
        "\n",
        "---\n",
        "\n",
        "## **Por que criar um Dataset?**  \n",
        "\n",
        "1. **Tomada de Decisão Baseada em Dados**  \n",
        "   - Empresas e pesquisadores utilizam datasets para fundamentar decisões estratégicas.  \n",
        "   - Um dataset bem construído ajuda a identificar padrões e tendências que podem ser usados para otimizar processos.  \n",
        "\n",
        "2. **Treinamento de Modelos de Machine Learning**  \n",
        "   - Modelos de IA precisam de dados para aprender e fazer previsões.  \n",
        "   - Sem um dataset de qualidade, o modelo pode gerar resultados imprecisos ou enviesados.  \n",
        "\n",
        "3. **Validação de Hipóteses e Estudos Estatísticos**  \n",
        "   - Pesquisadores usam datasets para testar hipóteses e comprovar teorias com base em dados reais.  \n",
        "   - Um dataset confiável garante resultados estatisticamente válidos.  \n",
        "\n",
        "4. **Automação e Otimização de Processos**  \n",
        "   - Em setores como logística, saúde e finanças, datasets ajudam a criar soluções automatizadas para previsões e recomendações.  \n",
        "   - Exemplos incluem previsões de demanda, diagnósticos médicos assistidos por IA e sistemas de recomendação em streaming e e-commerce.  \n",
        "\n",
        "5. **Armazenamento e Organização de Informações**  \n",
        "   - Criar um dataset facilita a organização de grandes volumes de informações.  \n",
        "   - Ele permite acesso rápido e estruturado para análises futuras.  \n",
        "\n",
        "---\n",
        "\n",
        "## **Estrutura de um Dataset**  \n",
        "\n",
        "Geralmente, um dataset é composto por:  \n",
        "\n",
        "- **Colunas (Atributos):** características dos dados (exemplo: idade, peso, altura, preço de um produto).  \n",
        "- **Linhas (Observações):** cada entrada representa uma instância única dentro do conjunto de dados.  \n",
        "- **Tipos de Dados:** numéricos (inteiros ou decimais), categóricos (sim/não, classes), textuais, etc.  \n",
        "\n",
        "### **Exemplo de Dataset (Tabela Simples)**  \n",
        "\n",
        "| ID  | Nome    | Idade | Salário (R$) | Cargo       |  \n",
        "|----|--------|------|-------------|------------|  \n",
        "| 1  | João   | 28   | 4.500       | Analista   |  \n",
        "| 2  | Maria  | 32   | 6.000       | Gerente    |  \n",
        "| 3  | Pedro  | 25   | 3.200       | Assistente |  \n",
        "\n",
        "Esse dataset poderia ser utilizado para analisar padrões salariais em uma empresa, estudar perfis de funcionários ou prever aumentos salariais com base em experiência.  \n",
        "\n",
        "---\n",
        "\n",
        "## **Como Criar um Dataset?**  \n",
        "\n",
        "Para criar um dataset de qualidade, siga algumas diretrizes:  \n",
        "\n",
        "✅ **Defina o objetivo**: O que você quer analisar ou prever?  \n",
        "✅ **Colete dados confiáveis**: Utilize fontes seguras e bem documentadas.  \n",
        "✅ **Estruture corretamente**: Escolha o formato adequado (CSV, JSON, SQL).  \n",
        "✅ **Realize limpeza e pré-processamento**: Remova valores ausentes e inconsistências.  \n",
        "✅ **Documente o dataset**: Explique os atributos para facilitar o entendimento.  \n",
        "\n",
        "---\n",
        "\n",
        "Criar um dataset bem estruturado e confiável é um passo fundamental para obter resultados precisos e relevantes em qualquer análise de dados."
      ],
      "metadata": {
        "id": "BFP-m6oZAs6b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPiNigrCnZ6s",
        "outputId": "6d93b85a-6f4c-4b2c-9230-30a7481f3116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo 'dados_aleatorios.csv' criado com sucesso!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Definir número de linhas\n",
        "num_linhas = 2_000_000\n",
        "\n",
        "# Gerar valores aleatórios seguindo distribuição normal\n",
        "idades = np.random.normal(loc=35, scale=10, size=num_linhas).astype(int)  # Idade inteira\n",
        "alturas = np.random.normal(loc=1.70, scale=0.1, size=num_linhas).round(2)  # Altura com 2 casas decimais\n",
        "numeros = np.random.normal(loc=5000, scale=1500, size=num_linhas).round(0)  # Números com 2 casas decimais\n",
        "\n",
        "# Criar DataFrame\n",
        "df = pd.DataFrame({'Idade': idades, 'Altura': alturas, 'NumeroAleatorio': numeros})\n",
        "\n",
        "# Salvar em CSV\n",
        "df.to_csv(\"dados_aleatorios.csv\", index=False, sep=';')\n",
        "\n",
        "print(\"Arquivo 'dados_aleatorios.csv' criado com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gera dataset com pontos fora da curva"
      ],
      "metadata": {
        "id": "G4ENCYDRoqf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Definir número de linhas e percentual de outliers\n",
        "num_linhas = 2_000_000\n",
        "percentual_outliers = 0.01  # 1%\n",
        "\n",
        "# Número de outliers\n",
        "num_outliers = int(num_linhas * percentual_outliers)\n",
        "num_normais = num_linhas - num_outliers\n",
        "\n",
        "# Função para gerar valores com outliers\n",
        "def gerar_dados(media, desvio, num_normais, num_outliers):\n",
        "    # 99% dos valores seguem a distribuição normal\n",
        "    valores_normais = np.random.normal(loc=media, scale=desvio, size=num_normais)\n",
        "\n",
        "    # 1% dos valores são outliers (acima ou abaixo de 3 desvios padrão)\n",
        "    outliers_superiores = np.random.normal(loc=media + 3 * desvio, scale=desvio, size=num_outliers // 2)\n",
        "    outliers_inferiores = np.random.normal(loc=media - 3 * desvio, scale=desvio, size=num_outliers // 2)\n",
        "\n",
        "    # Concatenar e embaralhar os valores\n",
        "    valores = np.concatenate((valores_normais, outliers_superiores, outliers_inferiores))\n",
        "    np.random.shuffle(valores)\n",
        "\n",
        "    return valores\n",
        "\n",
        "# Gerar dados com outliers\n",
        "idades = gerar_dados(media=35, desvio=10, num_normais=num_normais, num_outliers=num_outliers).astype(int)\n",
        "alturas = gerar_dados(media=1.70, desvio=0.1, num_normais=num_normais, num_outliers=num_outliers).round(2)\n",
        "numeros = gerar_dados(media=5000, desvio=1500, num_normais=num_normais, num_outliers=num_outliers).round(2)\n",
        "\n",
        "# Criar DataFrame\n",
        "df = pd.DataFrame({'Idade': idades, 'Altura': alturas, 'Numero Aleatorio': numeros})\n",
        "\n",
        "# Salvar em CSV\n",
        "df.to_csv(\"dados_aleatorios_com_outliers.csv\", index=False, sep=';')\n",
        "\n",
        "print(\"Arquivo 'dados_aleatorios_com_outliers.csv' criado com sucesso!\")\n"
      ],
      "metadata": {
        "id": "9sY2NIZEneRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde3eda9-397c-4c3f-9197-983e7688a099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo 'dados_aleatorios_com_outliers.csv' criado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "HE-1_aFHye4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indice de confiabilidade"
      ],
      "metadata": {
        "id": "zlODJlbuygH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Explicação**  \n",
        "\n",
        "O **intervalo de confiança (IC)** é um conceito estatístico que representa uma **faixa de valores onde a média verdadeira de uma população provavelmente se encontra**, com um determinado **nível de confiança**. Ele é amplamente utilizado para inferir sobre populações com base em amostras.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "2THtk-0Jyjky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **1. O Que é um Intervalo de Confiança?**\n",
        "Quando realizamos uma pesquisa, geralmente trabalhamos com **amostras**, pois medir toda a população pode ser inviável.  \n",
        "O **intervalo de confiança** fornece um **intervalo estimado** dentro do qual **esperamos que a verdadeira média da população esteja**.  \n",
        "\n",
        "Por exemplo, se dissermos que a **média de idade de uma população** tem um **intervalo de confiança de 95% entre 32 e 38 anos**, isso significa que **se repetirmos o estudo várias vezes**, em **95% das vezes** o intervalo conterá a média real da população.\n",
        "\n",
        "### **Importante:**\n",
        "- **O intervalo de confiança NÃO afirma que a média está dentro dele com certeza absoluta**.\n",
        "- **O intervalo muda se pegarmos outra amostra**, mas manterá a mesma interpretação estatística.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Fórmula do Intervalo de Confiança**\n",
        "Para calcular um intervalo de confiança para a **média de uma população**, usamos a seguinte fórmula:\n",
        "\n",
        "$IC = \\bar{x} \\pm Z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}$\n",
        "\n",
        "Onde:\n",
        "- $ \\bar{x} $ = **média da amostra**  \n",
        "- $ Z_{\\alpha/2} $ = **valor crítico da distribuição normal** (depende do nível de confiança)  \n",
        "- $ \\sigma $ = **desvio padrão da amostra (ou populacional, se conhecido)**  \n",
        "- $ n $ = **tamanho da amostra**  \n",
        "- $ \\frac{\\sigma}{\\sqrt{n}} $ = **erro padrão da média**  \n",
        "\n",
        "### **Componentes da Fórmula**\n",
        "1. **$ \\bar{x} $** → A média calculada a partir da amostra.\n",
        "2. **$ \\frac{\\sigma}{\\sqrt{n}} $** → O erro padrão, que mede a incerteza na média da amostra.\n",
        "3. **$ Z_{\\alpha/2} $** → O fator de confiança, que depende do nível de confiança escolhido.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Como Escolher o Nível de Confiança?**\n",
        "O **nível de confiança** representa a probabilidade de que o intervalo contenha a verdadeira média populacional.\n",
        "\n",
        "### **Valores Comuns de Confiança**\n",
        "| **Nível de Confiança** | **Valor Crítico $( Z_{\\alpha/2} $)** |\n",
        "|------------------------|--------------------------------|\n",
        "| 90%                   | 1.645                          |\n",
        "| 95%                   | 1.960                          |\n",
        "| 98%                   | 2.326                          |\n",
        "| 99%                   | 2.576                          |\n",
        "\n",
        "### **Interpretação**\n",
        "- **99% de confiança** → Maior certeza, mas intervalo mais amplo.  \n",
        "- **95% de confiança** → O mais comum em pesquisas científicas.  \n",
        "- **90% de confiança** → Intervalo menor, mas menor certeza.  \n",
        "\n",
        "Se queremos **maior precisão**, usamos um **nível menor**. Se queremos **mais certeza**, usamos **níveis mais altos**.\n",
        "\n",
        "---\n",
        "\n",
        "## **4. O Que Afeta o Intervalo de Confiança?**\n",
        "O **tamanho do intervalo** depende de três fatores principais:\n",
        "\n",
        "1. **Tamanho da amostra ($ n $)**  \n",
        "   - **Quanto maior a amostra**, menor o intervalo → **mais preciso**.  \n",
        "   - **Quanto menor a amostra**, maior o intervalo → **menos preciso**.  \n",
        "\n",
        "2. **Desvio padrão ($ \\sigma $)**  \n",
        "   - **Se os dados são muito dispersos**, o IC será maior.  \n",
        "   - **Se os dados são mais homogêneos**, o IC será menor.  \n",
        "\n",
        "3. **Nível de confiança ($ 1 - \\alpha $)**  \n",
        "   - **Maior confiança → Intervalo maior**.  \n",
        "   - **Menor confiança → Intervalo menor**.  \n",
        "\n",
        "### **Resumo dos Efeitos**\n",
        "| **Fator**                 | **Aumenta o IC** | **Diminui o IC** |\n",
        "|--------------------------|----------------|----------------|\n",
        "| **Aumentar a amostra**   | ❌            | ✅            |\n",
        "| **Maior desvio padrão**  | ✅            | ❌            |\n",
        "| **Maior nível de confiança** | ✅            | ❌            |\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Exemplo Prático**\n",
        "Suponha que queremos estimar a **idade média** de alunos em uma universidade.  \n",
        "Selecionamos uma **amostra de 100 alunos**, e encontramos:\n",
        "\n",
        "- **Média da amostra ($ \\bar{x} $)** = 25 anos  \n",
        "- **Desvio padrão ($ \\sigma $)** = 4 anos  \n",
        "- **Tamanho da amostra ($ n $)** = 100  \n",
        "\n",
        "Queremos calcular um **intervalo de confiança de 95%**.\n",
        "\n",
        "1. **Erro padrão da média:**\n",
        "   $   \\frac{\\sigma}{\\sqrt{n}} = \\frac{4}{\\sqrt{100}} = \\frac{4}{10} = 0.4 $\n",
        "\n",
        "2. **Valor crítico para 95% ($ Z_{\\alpha/2} $)**:\n",
        "   $\n",
        "   Z = 1.960\n",
        "   $\n",
        "\n",
        "3. **Cálculo da margem de erro:**\n",
        "   $ 1.960 \\times 0.4 = 0.784 $\n",
        "\n",
        "4. **Intervalo de Confiança:**\n",
        "   $  25 \\pm 0.784 $\n",
        "   $   [24.216, 25.784] $\n",
        "\n",
        "Isso significa que **temos 95% de certeza de que a verdadeira média da idade dos alunos está entre 24,22 e 25,78 anos**.\n",
        "\n",
        "---\n",
        "\n",
        "## **6. Intervalo de Confiança e Amostras Pequenas**\n",
        "Se a **amostra for pequena** ($ n < 30 $) e a distribuição não for normal, usamos a **distribuição t de Student** em vez da distribuição normal.\n",
        "\n",
        "A fórmula muda para:\n",
        "\n",
        "$ IC = \\bar{x} \\pm t_{\\alpha/2} \\times \\frac{s}{\\sqrt{n}} $\n",
        "\n",
        "Onde:\n",
        "- $ t_{\\alpha/2} $ → Valor crítico da distribuição t, baseado nos graus de liberdade $ (n - 1) $.\n",
        "- $ s $ → Desvio padrão da amostra.\n",
        "\n",
        "O **intervalo será maior**, pois há mais incerteza com amostras pequenas.\n",
        "\n",
        "---\n",
        "\n",
        "## **7. Aplicações do Intervalo de Confiança**\n",
        "O IC é usado em diversas áreas:\n",
        "- **Pesquisa médica** → Para estimar a eficácia de tratamentos.\n",
        "- **Economia** → Para prever médias salariais.\n",
        "- **Ciências sociais** → Para analisar populações com base em amostras.\n",
        "- **Machine Learning** → Para avaliar modelos preditivos.\n",
        "\n",
        "---\n",
        "\n",
        "## **8. Conclusão**\n",
        "✔ O **Intervalo de Confiança** fornece uma faixa de valores onde a **média populacional verdadeira** provavelmente está.  \n",
        "✔ **Depende do tamanho da amostra, variabilidade dos dados e nível de confiança.**  \n",
        "✔ **Níveis de confiança mais altos tornam o intervalo maior.**  \n",
        "✔ **Amostras pequenas exigem a distribuição t de Student.**  \n",
        "\n",
        "Se precisar de mais precisão:\n",
        "✅ **Aumente a amostra**  \n",
        "✅ **Aceite um nível de confiança menor (ex: 95%)**  \n"
      ],
      "metadata": {
        "id": "nmkCEft89nEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gerar dataset com confiabilidade"
      ],
      "metadata": {
        "id": "gvC0kMAPvj8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Importar os dados do questionário\n",
        "df = pd.read_csv('/content/dados_aleatorios.csv', sep=';')\n",
        "\n",
        "# Extrair a coluna de idade como amostra\n",
        "amostra = df['Idade'].dropna().astype(int)  # Removendo valores nulos e garantindo tipo inteiro\n",
        "\n",
        "# Estatísticas da amostra\n",
        "media_amostra = np.mean(amostra)\n",
        "desvio_amostra = np.std(amostra, ddof=1)  # ddof=1 para amostra\n",
        "\n",
        "# Definir nível de confiança (99%)\n",
        "z_score = norm.ppf(0.995)  # Valor crítico para 99% (~2.576)\n",
        "erro_maximo = 2  # Erro aceitável (ajuste conforme necessário)\n",
        "\n",
        "# Calcular tamanho da amostra necessária\n",
        "n_necessario = (z_score * desvio_amostra / erro_maximo) ** 2\n",
        "n_necessario = int(np.ceil(n_necessario))  # Arredondar para cima\n",
        "\n",
        "print(f\"Tamanho mínimo necessário da amostra: {n_necessario}\")\n",
        "\n",
        "# Gerar novos dados baseados na amostra original\n",
        "idades_finais = np.random.normal(loc=media_amostra, scale=desvio_amostra, size=n_necessario).astype(int)\n",
        "\n",
        "# Criar DataFrame final\n",
        "df_final = pd.DataFrame({'Idade': idades_finais})\n",
        "\n",
        "# Salvar CSV\n",
        "df_final.to_csv(\"dataset_confiavel.csv\", index=False, sep=';')\n",
        "\n",
        "print(\"Dataset confiável gerado e salvo como 'dataset_confiavel.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pkztm-V1xcvb",
        "outputId": "45e33f21-5cb3-4da9-bc14-fae7f1ea2ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho mínimo necessário da amostra: 166\n",
            "Dataset confiável gerado e salvo como 'dataset_confiavel.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo Questionario"
      ],
      "metadata": {
        "id": "NndR7UzjxYdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Importar os dados do questionário\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/luiscarlosjunior/aulas-graduacao/refs/heads/master/data-science/analise-dados/datasets/csv/questionario.csv', sep=';')\n",
        "\n",
        "# Extrair a coluna de idade como amostra\n",
        "amostra = df['idade'].dropna().astype(int)  # Removendo valores nulos e garantindo tipo inteiro\n",
        "\n",
        "# Estatísticas da amostra\n",
        "media_amostra = np.mean(amostra)\n",
        "desvio_amostra = np.std(amostra, ddof=1)  # ddof=1 para amostra\n",
        "\n",
        "# Definir nível de confiança (99%)\n",
        "z_score = norm.ppf(0.995)  # Valor crítico para 99% (~2.576)\n",
        "erro_maximo = 2  # Erro aceitável (ajuste conforme necessário)\n",
        "\n",
        "# Calcular tamanho da amostra necessária\n",
        "n_necessario = (z_score * desvio_amostra / erro_maximo) ** 2\n",
        "n_necessario = int(np.ceil(n_necessario))  # Arredondar para cima\n",
        "\n",
        "print(f\"Tamanho mínimo necessário da amostra: {n_necessario}\")\n",
        "\n",
        "# Gerar novos dados baseados na amostra original\n",
        "idades_finais = np.random.normal(loc=media_amostra, scale=desvio_amostra, size=n_necessario).astype(int)\n",
        "\n",
        "# Criar DataFrame final\n",
        "df_final = pd.DataFrame({'Idade': idades_finais})\n",
        "\n",
        "# Salvar CSV\n",
        "df_final.to_csv(\"dataset_confiavel.csv\", index=False, sep=';')\n",
        "\n",
        "print(\"Dataset confiável gerado e salvo como 'dataset_confiavel.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7s7i8pFvm1y",
        "outputId": "d3c80477-9d5a-4d9c-9145-9a88307ab578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho mínimo necessário da amostra: 45\n",
            "Dataset confiável gerado e salvo como 'dataset_confiavel.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explicação do resultado\n",
        "\n",
        "O resultado de **45** como o tamanho mínimo necessário da amostra, apesar de sua amostra original ter **74 valores**, ocorre porque o cálculo do tamanho da amostra está baseado no **intervalo de confiança**, na **variabilidade dos dados** e no **erro máximo permitido**. Vamos analisar o que isso significa.  \n",
        "\n",
        "---\n",
        "\n",
        "#### **Por que o tamanho mínimo da amostra pode ser menor que o total de dados disponíveis?**\n",
        "A fórmula usada para estimar o tamanho da amostra foi:\n",
        "\n",
        "$n = \\left( \\frac{Z_{\\alpha/2} \\times \\sigma}{E} \\right)^2$\n",
        "\n",
        "Onde:\n",
        "- $ Z_{\\alpha/2} = 2.576 $ (valor crítico para 99% de confiança)\n",
        "- $ \\sigma $ = desvio padrão da amostra\n",
        "- $ E = 2 $ (erro máximo aceitável)\n",
        "\n",
        "O resultado **45** significa que **para garantir um intervalo de confiança de 99% com erro máximo de 2 unidades, apenas 45 amostras são estatisticamente necessárias**.\n",
        "\n",
        "Se a variabilidade (desvio padrão) dos dados não for muito alta, então **menos amostras são suficientes para representar a população**. Ou seja, sua amostra inicial de **74** pode conter **redundância estatística**, o que explica porque apenas **45 já são suficientes**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Cenários possíveis**\n",
        "1. **Se a variabilidade da amostra fosse maior**  \n",
        "   → **Maior desvio padrão** → **Precisaria de mais dados para confiabilidade**\n",
        "   \n",
        "2. **Se reduzíssemos o erro máximo permitido (E)**  \n",
        "   → **Exigir um erro de 1 ao invés de 2** aumentaria **n** para melhorar a precisão.\n",
        "   \n",
        "3. **Se tivéssemos escolhido um nível de confiança menor (ex: 95%)**  \n",
        "   → O valor crítico $ Z_{\\alpha/2} $ seria **1.96**, diminuindo **n**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **O que fazer com esse resultado?**\n",
        "- **Se quiser usar todos os 74 valores**, não há problema! Isso pode até melhorar a robustez dos dados.  \n",
        "- **Se quiser um dataset confiável mínimo**, os **45 valores aleatórios gerados** já são suficientes.  \n",
        "- **Se precisar de mais precisão**, diminua o erro $ E $ para aumentar o tamanho necessário da amostra.\n",
        "\n",
        "Resumindo: **o número 45 é um limite mínimo estatístico, mas você pode continuar usando a amostra maior sem problemas!**"
      ],
      "metadata": {
        "id": "L6HfzbzYw7VB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R5V8yfi_wBTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplo Tabela de distribuição de frequência com dataset criado"
      ],
      "metadata": {
        "id": "FMu3IU3y-wdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/dados_aleatorios_com_outliers.csv', sep=';')\n",
        "\n",
        "df_filtrado = df[df['Idade'] > 0]\n",
        "\n",
        "# Nome da coluna a ser analisada\n",
        "coluna = 'Idade'\n",
        "\n",
        "# Definir automaticamente os intervalos usando numpy\n",
        "num_classes = 10  # Número de classes (ajuste conforme necessário)\n",
        "bins = np.histogram_bin_edges(df_filtrado[coluna], bins=num_classes)\n",
        "\n",
        "# Criar rótulos automaticamente\n",
        "labels = [f\"{int(bins[i])}-{int(bins[i+1])}\" for i in range(len(bins)-1)]\n",
        "\n",
        "# Criar a tabela de frequência agrupada\n",
        "df['Classe'] = pd.cut(df_filtrado[coluna], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Calcular as colunas da distribuição de frequência\n",
        "tabela_freq = df['Classe'].value_counts().sort_index().reset_index()\n",
        "tabela_freq.columns = ['Classe', 'f']  # f = Frequência Absoluta\n",
        "tabela_freq['F'] = tabela_freq['f'].cumsum()  # Frequência Acumulada\n",
        "tabela_freq['fr'] = tabela_freq['f'] / tabela_freq['f'].sum()  # Frequência Relativa\n",
        "tabela_freq['fp (%)'] = tabela_freq['fr'] * 100  # Frequência Percentual\n",
        "\n",
        "# Adicionar a linha de totais\n",
        "totais = {\n",
        "    'Classe': 'Total',\n",
        "    'f': tabela_freq['f'].sum(),\n",
        "    'F': '',  # Não faz sentido somar a frequência acumulada\n",
        "    'fr': tabela_freq['fr'].sum(),\n",
        "    'fp (%)': tabela_freq['fp (%)'].sum()\n",
        "}\n",
        "\n",
        "# Adiciona os totais à tabela\n",
        "tabela_freq = pd.concat([tabela_freq, pd.DataFrame([totais])], ignore_index=True)\n",
        "\n",
        "# Exibir a tabela\n",
        "print(tabela_freq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SdwyXmd8fcQ",
        "outputId": "a5234026-7221-4d92-e7a7-2ff74713c6a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Classe        f        F        fr      fp (%)\n",
            "0    1-10    19564    19564  0.009802    0.980223\n",
            "1   10-20   145982   165546  0.073142    7.314193\n",
            "2   20-30   524052   689598  0.262568   26.256781\n",
            "3   30-40   753847  1443445  0.377703   37.770289\n",
            "4   40-50   411122  1854567  0.205986   20.598605\n",
            "5   50-59   121985  1976552  0.061119    6.111862\n",
            "6   59-69    15777  1992329  0.007905    0.790481\n",
            "7   69-79     2880  1995209  0.001443    0.144298\n",
            "8   79-89      613  1995822  0.000307    0.030713\n",
            "9   89-99       51  1995873  0.000026    0.002555\n",
            "10  Total  1995873           1.000000  100.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OUrPoIw8ryh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}